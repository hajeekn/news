<!DOCTYPE html><html lang=zh-CN><head hexo-theme=https://github.com/volantis-x/hexo-theme-volantis/tree/4.3.1><meta charset=utf-8><meta http-equiv=x-dns-prefetch-control content=on><link rel=dns-prefetch href=https://cdn.jsdelivr.net><link rel=preconnect href=https://cdn.jsdelivr.net crossorigin><meta name=renderer content=webkit><meta name=force-rendering content=webkit><meta http-equiv=X-UA-Compatible content="IE=Edge,chrome=1"><meta name=HandheldFriendly content=True><meta name=apple-mobile-web-app-capable content=yes><meta name=viewport content="width=device-width, initial-scale=1, maximum-scale=1"><link rel=preload href=/css/first.css as=style><title>ACL 2021｜美团提出基于对比学习的文本表示模型，效果相比BERT-flow提升8% - Hajeekn RSSHUB</title><link rel=alternate href=/atom.xml title="Hajeekn RSSHUB" type=application/atom+xml><meta name=referrer content=no-referrer><link rel=stylesheet href=/css/diy.css><link rel=stylesheet href=/css/first.css><link rel=stylesheet href=/css/style.css media=print onload="this.media='all';this.onload=null"><noscript><link rel=stylesheet href=/css/style.css></noscript><script id=loadcss></script><script>
if (/*@cc_on!@*/false || (!!window.MSInputMethodContext && !!document.documentMode))
    document.write(
	'<style>'+
		'html{'+
			'overflow-x: hidden !important;'+
			'overflow-y: hidden !important;'+
		'}'+
		'.kill-ie{'+
			'text-align:center;'+
			'height: 100%;'+
			'margin-top: 15%;'+
			'margin-bottom: 5500%;'+
		'}'+
	'</style>'+
    '<div class="kill-ie">'+
        '<h1><b>抱歉，您的浏览器无法访问本站</b></h1>'+
        '<h3>微软已经于2016年终止了对 Internet Explorer (IE) 10 及更早版本的支持，<br/>'+
        '继续使用存在极大的安全隐患，请使用当代主流的浏览器进行访问。</h3><br/>'+
        '<a target="_blank" rel="noopener" href="https://www.microsoft.com/zh-cn/WindowsForBusiness/End-of-IE-support"><strong>了解详情 ></strong></a>'+
    '</div>');
</script><noscript><style>
		html{
			overflow-x: hidden !important;
			overflow-y: hidden !important;
		}
		.kill-noscript{
			text-align:center;
			height: 100%;
			margin-top: 15%;
			margin-bottom: 5500%;
		}
	</style><div class=kill-noscript><h1><b>抱歉，您的浏览器无法访问本站</b></h1><h3>本页面需要浏览器支持（启用）JavaScript</h3><br><a target=_blank rel=noopener href="https://www.baidu.com/s?wd=启用JavaScript"><strong>了解详情 ></strong></a></div></noscript></head><body><header id=l_header class="l_header always shadow blur show"><div class=container><div id=wrapper><div class=nav-sub><p class=title></p><ul class="switcher nav-list-h m-phone" id=pjax-header-nav-list><li><a id=s-comment class="fas fa-comments fa-fw" target=_self href=javascript:void(0)></a></li><li><a id=s-toc class="s-toc fas fa-list fa-fw" target=_self href=javascript:void(0)></a></li></ul></div><div class=nav-main><a class="title flat-box" target=_self href="/"><img no-lazy class=logo src=https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/blog/Logo-NavBar@3x.png></a><div class="menu navigation"><ul class="nav-list-h m-pc"><li><a class="menuitem flat-box faa-parent animated-hover" href="/" id=home><i class="fas fa-home fa-fw fa-fw"></i> 主页</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/categories/%E5%8D%9A%E5%AE%A2/" id=categoriesE58D9AE5AEA2><i class="fas fa-rss fa-fw"></i> 博客订阅</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/categories/%E6%96%B0%E5%AA%92%E4%BD%93/" id=categoriesE696B0E5AA92E4BD93><i class="fas fa-podcast fa-fw fa-fw"></i> 新媒体</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/categories/%E4%BA%8C%E6%AC%A1%E5%85%83/" id=categoriesE4BA8CE6ACA1E58583><i class="fas fa-heart fa-fw fa-fw"></i> 二次元</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/categories/%E6%B8%B8%E6%88%8F/" id=categoriesE6B8B8E6888F><i class="fa fa-gamepad fa-fw fa-fw"></i> 游戏</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/categories/%E5%9B%BE%E7%89%87/" id=categoriesE59BBEE78987><i class="fas fa-puzzle-piece fa-fw fa-fw"></i> 图片</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/categories/%E8%AE%BE%E8%AE%A1/" id=categoriesE8AEBEE8AEA1><i class="fas fa-magic fa-fw fa-fw"></i> 设计</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/categories/%E7%BC%96%E7%A8%8B/" id=categoriesE7BC96E7A88B><i class="fas fa-code fa-fw fa-fw"></i> 编程</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/categories/%E9%87%91%E8%9E%8D/" id=categoriesE98791E89E8D><i class="fas fa-key fa-fw fa-fw"></i> 金融</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/categories/%E7%A4%BE%E4%BA%A4%E5%AA%92%E4%BD%93/" id=categoriesE7A4BEE4BAA4E5AA92E4BD93><i class="fas fa-users fa-fw fa-fw"></i> 社交媒体</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/categories/%E9%98%85%E8%AF%BB/" id=categoriesE99885E8AFBB><i class="fas fa-book fa-fw fa-fw"></i> 阅读</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/categories/%E5%AD%A6%E4%B9%A0/" id=categoriesE5ADA6E4B9A0><i class="fas fa-graduation-cap fa-fw fa-fw"></i> 学习</a></li></ul></div><div class=m_search><form name=searchform class="form u-search-form"><i class="icon fas fa-search fa-fw"></i> <input type=text class="input u-search-input" placeholder=Search...></form></div><ul class="switcher nav-list-h m-phone"><li><a class="s-search fas fa-search fa-fw" target=_self href=javascript:void(0)></a></li><li><a class="s-menu fas fa-bars fa-fw" target=_self href=javascript:void(0)></a><ul class="menu-phone list-v navigation white-box"><li><a class="menuitem flat-box faa-parent animated-hover" href="/" id=home><i class="fas fa-home fa-fw fa-fw"></i> 主页</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/categories/%E5%8D%9A%E5%AE%A2/" id=categoriesE58D9AE5AEA2><i class="fas fa-rss fa-fw"></i> 博客订阅</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/categories/%E6%96%B0%E5%AA%92%E4%BD%93/" id=categoriesE696B0E5AA92E4BD93><i class="fas fa-podcast fa-fw fa-fw"></i> 新媒体</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/categories/%E4%BA%8C%E6%AC%A1%E5%85%83/" id=categoriesE4BA8CE6ACA1E58583><i class="fas fa-heart fa-fw fa-fw"></i> 二次元</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/categories/%E6%B8%B8%E6%88%8F/" id=categoriesE6B8B8E6888F><i class="fa fa-gamepad fa-fw fa-fw"></i> 游戏</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/categories/%E5%9B%BE%E7%89%87/" id=categoriesE59BBEE78987><i class="fas fa-puzzle-piece fa-fw fa-fw"></i> 图片</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/categories/%E8%AE%BE%E8%AE%A1/" id=categoriesE8AEBEE8AEA1><i class="fas fa-magic fa-fw fa-fw"></i> 设计</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/categories/%E7%BC%96%E7%A8%8B/" id=categoriesE7BC96E7A88B><i class="fas fa-code fa-fw fa-fw"></i> 编程</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/categories/%E9%87%91%E8%9E%8D/" id=categoriesE98791E89E8D><i class="fas fa-key fa-fw fa-fw"></i> 金融</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/categories/%E7%A4%BE%E4%BA%A4%E5%AA%92%E4%BD%93/" id=categoriesE7A4BEE4BAA4E5AA92E4BD93><i class="fas fa-users fa-fw fa-fw"></i> 社交媒体</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/categories/%E9%98%85%E8%AF%BB/" id=categoriesE99885E8AFBB><i class="fas fa-book fa-fw fa-fw"></i> 阅读</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/categories/%E5%AD%A6%E4%B9%A0/" id=categoriesE5ADA6E4B9A0><i class="fas fa-graduation-cap fa-fw fa-fw"></i> 学习</a></li></ul></li></ul></div></div></div></header><div id=l_body><div id=l_cover><div id=full class="cover-wrapper post dock" style="display: none;"><div class="cover-bg lazyload placeholder" data-bg="https://uploadbeta.com/api/pictures/random/?key=BingEverydayWallpaperPicture"></div><div class=cover-body><div class=top><p class=title>Volantis</p></div><div class=bottom><div class="menu navigation"><div class=list-h><a href="/v4/getting-started/" id=v4getting-started><img src=https://cdn.jsdelivr.net/gh/twitter/twemoji@13.0/assets/svg/1f5c3.svg><p>文档</p></a> <a href="/faqs/" id=faqs><img src=https://cdn.jsdelivr.net/gh/twitter/twemoji@13.0/assets/svg/1f516.svg><p>帮助</p></a> <a href="/examples/" id=examples><img src=https://cdn.jsdelivr.net/gh/twitter/twemoji@13.0/assets/svg/1f396.svg><p>示例</p></a> <a href="/contributors/" id=contributors><img src=https://cdn.jsdelivr.net/gh/twitter/twemoji@13.0/assets/svg/1f389.svg><p>社区</p></a> <a href="/archives/" id=archives><img src=https://cdn.jsdelivr.net/gh/twitter/twemoji@13.0/assets/svg/1f4f0.svg><p>博客</p></a> <a target=_blank rel=noopener href="https://github.com/volantis-x/hexo-theme-volantis/" id=https:githubcomvolantis-xhexo-theme-volantis><img src=https://cdn.jsdelivr.net/gh/twitter/twemoji@13.0/assets/svg/1f9ec.svg><p>源码</p></a></div></div></div></div><div id=scroll-down style="display: none;"><i class="fa fa-chevron-down scroll-down-effects"></i></div></div></div><div id=safearea><div class=body-wrapper id=pjax-container><div class=l_main><article class="article post white-box reveal md shadow article-type-post" id=post itemscope itemprop=blogPost><div class=headimg-div><a class=headimg-a><img class=headimg src=https://p0.meituan.net/travelcube/5f9553f85be65f3dbf8fd0dd1497c29f246638.png></a></div><div class=article-meta id=top><a title="ACL 2021｜美团提出基于对比学习的文本表示模型，效果相比BERT-flow提升8%" href=/p/16b3.html><img class=thumbnail src=https://p0.meituan.net/travelcube/5f9553f85be65f3dbf8fd0dd1497c29f246638.png></a><h1 class=title>ACL 2021｜美团提出基于对比学习的文本表示模型，效果相比BERT-flow提升8%</h1><div class=new-meta-box><div class="new-meta-item author"><a class=author target=_blank href="https://docs.rsshub.app/" rel="nofollow noopener"><img no-lazy src=https://i.loli.net/2019/04/23/5cbeb7e41414c.png><p>RSSHub</p></a></div><div class="new-meta-item category"><a class=notlink><i class="fas fa-folder-open fa-fw" aria-hidden=true></i> <a class=category-link href="/categories/%E5%8D%9A%E5%AE%A2/">博客</a><span class=sep></span><a class=category-link href="/categories/%E5%8D%9A%E5%AE%A2/%E7%BE%8E%E5%9B%A2%E6%8A%80%E6%9C%AF%E5%9B%A2%E9%98%9F/">美团技术团队</a><span class=sep></span><a class=category-link href="/categories/%E5%8D%9A%E5%AE%A2/%E7%BE%8E%E5%9B%A2%E6%8A%80%E6%9C%AF%E5%9B%A2%E9%98%9F/%E6%9C%80%E8%BF%91%E6%9B%B4%E6%96%B0/">最近更新</a></a></div><div class="new-meta-item date"><a class=notlink><i class="fas fa-calendar-alt fa-fw" aria-hidden=true></i><p>发布于：2021年6月3日</p></a></div><div class="new-meta-item browse leancloud"><a class=notlink><div id=lc-pv data-title="ACL 2021｜美团提出基于对比学习的文本表示模型，效果相比BERT-flow提升8%" data-path=/p/16b3.html><i class="fas fa-eye fa-fw" aria-hidden=true></i><span id=number><i class="fas fa-circle-notch fa-spin fa-fw" aria-hidden=true></i></span> 次浏览</div></a></div></div></div><div><p>尽管基于BERT的模型在NLP诸多下游任务中取得了成功，直接从BERT导出的句向量表示往往被约束在一个很小的区域内，表现出很高的相似度，因而难以直接用于文本语义匹配。为解决BERT原生句子表示这种“坍缩”现象，美团NLP中心知识图谱团队提出了基于对比学习的句子表示迁移方法——ConSERT，通过在目标领域的无监督语料上Fine-tune，使模型生成的句子表示与下游任务的数据分布更加适配。在句子语义匹配（STS）任务的实验结果显示，同等设置下ConSERT相比此前的SOTA（BERT-flow）大幅提升了8%，并且在少样本场景下仍表现出较强的性能提升。</p><ul><li>论文：《ConSERT: A Contrastive Framework for Self-Supervised Sentence Representation Transfer》</li><li>会议：ACL 2021</li><li>下载链接：<a target=_blank rel=noopener href=https://arxiv.org/abs/2105.11741>https://arxiv.org/abs/2105.11741</a></li><li>开源代码：<a target=_blank rel=noopener href=https://github.com/yym6472/ConSERT>https://github.com/yym6472/ConSERT</a></li></ul><h2 id=1-背景>1. 背景</h2><p>句向量表示学习在自然语言处理（NLP）领域占据重要地位，许多NLP任务的成功离不开训练优质的句子表示向量。特别是在文本语义匹配（Semantic Textual Similarity）、文本向量检索（Dense Text Retrieval）等任务上，模型通过计算两个句子编码后的Embedding在表示空间的相似度来衡量这两个句子语义上的相关程度，从而决定其匹配分数。</p><p>尽管基于BERT的模型在诸多NLP任务上取得了不错的性能（通过有监督的Fine-tune），但其自身导出的句向量（不经过Fine-tune，对所有词向量求平均）质量较低，甚至比不上Glove的结果，因而难以反映出两个句子的语义相似度$^\text&#123;[1][2][3][4]&#125;$。我们在研究的过程中进一步分析了BERT导出的句向量所具有的特性，证实了以下两点：</p><p>1.BERT对所有的句子都倾向于编码到一个较小的空间区域内，这使得大多数的句子对都具有较高的相似度分数，即使是那些语义上完全无关的句子对（如图1a所示）。我们将此称为BERT句子表示的“坍缩（Collapse）”现象。</p><p><img src=https://p0.meituan.net/travelcube/5f9553f85be65f3dbf8fd0dd1497c29f246638.png class=lazyload data-srcset=https://p0.meituan.net/travelcube/5f9553f85be65f3dbf8fd0dd1497c29f246638.png srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图1 左：BERT表示空间的坍缩问题（横坐标是人工标注的相似度分数，纵坐标是模型预测的余弦相似度）；右：经过我们的方法Fine-tune之后" referrerpolicy=no-referrer></p><p>2.BERT句向量表示的坍缩和句子中的高频词有关。具体来说，当通过平均词向量的方式计算句向量时，那些高频词的词向量将会主导句向量，使之难以体现其原本的语义。当计算句向量时去除若干高频词时，坍缩现象可以在一定程度上得到缓解（如图2蓝色曲线所示）。</p><p><img src=https://p0.meituan.net/travelcube/c6d05fe3ba5923930b62b84513cc3c44186193.png class=lazyload data-srcset=https://p0.meituan.net/travelcube/c6d05fe3ba5923930b62b84513cc3c44186193.png srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图2 计算句向量时移除Top-K高频词后的性能变化" referrerpolicy=no-referrer></p><p>BERT导出的句向量难以直接用于下游的语义匹配任务，而用于Fine-tune的监督语料又是昂贵的。因此我们希望寻找一种自监督的方法，只需要收集少量来自于下游任务无标注的文本用于Fine-tune，就能解决BERT句向量的“坍缩”问题，同时让其表征更适用于下游任务。</p><p>在本文中，我们使用了对比学习（Contrastive Learning）来达到上述目的。对比学习是目前被广泛应用的自监督任务之一，其核心思想为：人类是通过“对比”来辨别对象的，因此相似的事物在编码后的表示空间中应当相近，不同的事物则应当相距尽可能远。通过对同一样本施加不同的数据增强方法，我们能够得到一系列“自相似”的文本对作为正例，同时将同一个Batch内的其他文本作为负例，以此为监督信号去规范BERT的表示空间。在实验中，我们发现对比学习能够出色地消解高频词对句子语义表示的干扰（如图2橙色曲线所示）。在经过对比学习训练之后，模型生成的句子表示将不再由高频词主导（体现在移除前几个高频词后，性能没有出现非常明显的变化）。这是因为对比学习“辨别自身”的学习目标能够天然地识别并抑制这类高频特征，从而避免语义相差较大的句子表示过于相近（即坍缩现象）。</p><p>在对比学习中，我们进一步分析了不同的数据增强方法在其中的影响，同时验证了我们的方法在少样本情况下的性能表现。实验结果显示，即使是在非常有限的数据量情况下（如1000条无标注样本），我们的方法仍然表现出很强的鲁棒性，能够十分有效地解决BERT表示空间的坍缩问题，提升在下游语义匹配任务上的指标。</p><h2 id=2-研究现状和相关工作>2. 研究现状和相关工作</h2><h3 id=2-1-句子表征学习>2.1 句子表征学习</h3><p>句子表征学习是一个很经典的任务，分为以下三个阶段：</p><ol><li>有监督的句子表征学习方法：早期的工作$^\text&#123;[5]&#125;$发现自然语言推理（Natural Language Inference，NLI）任务对语义匹配任务有较大的帮助，他们使用BiLSTM编码器，融合了两个NLI的数据集SNLI和MNLI进行训练。Universal Sentence Encoder$^\text&#123;[6]&#125;$（USE）使用了基于Transformer的架构，并使用SNLI对无监督训练进行增强。SBERT$^\text&#123;[1]&#125;$进一步使用了一个共享的预训练的BERT编码器对两个句子进行编码，在NLI数据集上进行训练（Fine-tune）。</li><li>自监督的Sentence-level预训练：有监督数据标注成本高，研究者们开始寻找无监督的训练方式。BERT提出了NSP的任务，可以算作是一种自监督的句子级预训练目标。尽管之后的工作指出NSP相比于MLM其实没有太大帮助。Cross-Thought$^\text&#123;[7]&#125;$、CMLM$^\text&#123;[8]&#125;$ 是两种思想类似的预训练目标，他们把一段文章切成多个短句，然后通过相邻句子的编码去恢复当前句子中被Mask的Token。相比于MLM，额外添加了上下文其他句子的编码对Token恢复的帮助，因此更适合句子级别的训练。SLM$^\text&#123;[9]&#125;$通过将原本连贯的若干个短句打乱顺序（通过改变Position Id实现），然后通过预测正确的句子顺序进行自监督预训练。</li><li>无监督的句子表示迁移：预训练模型现已被普遍使用，然而BERT的NSP任务得到的表示表现更不好，大多数同学也没有资源去进行自监督预训练，因此将预训练模型的表示迁移到任务才是更有效的方式。BERT-flow$^\text&#123;[2]&#125;$：CMU&字节AI Lab的工作，通过在BERT之上学习一个可逆的Flow变换，可以将BERT表示空间映射到规范化的标准高斯空间，然后在高斯空间进行相似度匹配。BERT-whitening$^\text&#123;[10]&#125;$：苏剑林和我们同期的工作。他们提出对BERT表征进行白化操作（均值变为0，协方差变为单位矩阵）就能在STS上达到媲美BERT-flow的效果。SimCSE$^\text&#123;[11]&#125;$：陈丹琦组在2021年4月份公开的工作。他们同样使用基于对比学习的训练框架，使用Dropout的数据增强方法，在维基百科语料上Fine-tune BERT。</li></ol><h3 id=2-2-对比学习>2.2 对比学习</h3><p>对比学习是CV领域从2019年末开始兴起的预训练方法，同时最近也被广泛应用到了NLP任务中，我们简要介绍两个领域下的进展：</p><ol><li>计算机视觉（CV）领域的对比学习：2019年年末～2020年年初，Facebook提出MoCo$^\text&#123;[14]&#125;$，谷歌提出SimCLR$^\text&#123;[15]&#125;$，自此对比学习开始在无监督图像表示预训练领域大放光彩。SimCLR提出了一种简单的对比学习框架，通过对同一个图像进行增强，得到两个不同版本，随后通过ResNet对图像编码，再使用一个映射层将其映射到对比学习空间，使用NT-Xent损失进行预训练。本文的框架也主要受到SimCLR的启发。</li><li>NLP领域的对比学习（用于文本表示学习）：随着对比学习在CV无监督图像表示预训练任务上大获成功，许多工作也试图将对比学习引入到NLP的语言模型预训练中。下面是一些代表性的工作及其总结：</li></ol><table><thead><tr><th>名称</th><th>结构</th><th>数据增强方法</th><th>作用阶段</th></tr></thead><tbody><tr><td>BERT-CT$^\text&#123;[18]&#125;$</td><td>用两个相同结构、不同参数的模型产生两个View</td><td>用两个相同结构、不同参数的模型产生两个View</td><td>微调BERT</td></tr><tr><td>IS-BERT$^\text&#123;[16]&#125;$</td><td>在BERT之上添加额外的CNN层</td><td>全局Embedding作为一个View；CNN层局部的Embedding作为另一个View</td><td>微调BERT，最大化全局Embedding和局部Embedding的互信息，类似DeepInfoMax（DIM）</td></tr><tr><td>CERT$^\text&#123;[17]&#125;$</td><td>类似MoCo，用一个动量编码器</td><td>回译</td><td>先在任务上用对比无监督精调，再迁到有监督任务</td></tr><tr><td>CLEAR$^\text&#123;[20]&#125;$</td><td>类似SimCLR</td><td>Token、Span的删除（Deletion）、交换位置（Reordering）、替换（Substitution）</td><td>预训练阶段，用MLM和对比损失联合训练模型</td></tr><tr><td>DeCLUTR$^\text&#123;[19]&#125;$</td><td>类似SimCLR</td><td>从文本中抽取Span</td><td>预训练阶段，用MLM和对比损失联合训练模型</td></tr></tbody></table><h2 id=3-模型介绍>3. 模型介绍</h2><h3 id=3-1-问题定义>3.1 问题定义</h3><p>给定一个类似BERT的预训练语言模型$\textbf&#123;M&#125;$，以及从目标领域数据分布中收集的无标签文本语料库$\mathcal&#123;D&#125;$，我们希望通过构建自监督任务在$\mathcal&#123;D&#125;$上对$\textbf&#123;M&#125;$进行Fine-tune，使得Fine-tune后的模型能够在目标任务（文本语义匹配）上表现最好。</p><h3 id=3-2-基于对比学习的句子表示迁移框架>3.2 基于对比学习的句子表示迁移框架</h3><p><img src=https://p0.meituan.net/travelcube/12fb23c7179d0a991a874fe9419e1310196618.png class=lazyload data-srcset=https://p0.meituan.net/travelcube/12fb23c7179d0a991a874fe9419e1310196618.png srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图3 ConSERT的基本框架" referrerpolicy=no-referrer></p><p>如图3所示，我们受到SimCLR的启发对BERT编码器进行了改进，提出ConSERT，主要包含三个部分：</p><ul><li>一个数据增强模块（详见后文），作用于Embedding层，为同一个句子生成两个不同的增强版本（View）。</li><li>一个共享的BERT编码器，为输入的句子生成句向量。</li><li>一个对比损失层，用于在一个Batch的样本中计算对比损失，其思想是最大化同一个样本不同增强版本句向量的相似度，同时使得不同样本的句向量相互远离。</li></ul><p>训练时，先从数据集$\mathcal&#123;D&#125;$中采样一个Batch的文本，设Batch size为$N$。通过数据增强模块，每一个样本都通过两种预设的数据增强方法生成两个版本，得到总共$2N$条样本。这$2N$条样本均会通过共享的BERT编码器进行编码，然后通过一个平均池化层，得到$2N$个句向量。我们采用和SimCLR一致的NT-Xent损失对模型进行Fine-tune：</p><p><img src=https://p0.meituan.net/travelcube/1a6b6c8c5f1b9c32376720ae3dd1d0e639649.png class=lazyload data-srcset=https://p0.meituan.net/travelcube/1a6b6c8c5f1b9c32376720ae3dd1d0e639649.png srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" referrerpolicy=no-referrer></p><p>这里的$\text&#123;sim&#125;()$函数为余弦相似度函数；$r$表示对应的句向量；$\tau$表示temperature，是一个超参数，实验中取0.1。该损失从直观上理解，是让Batch内的每个样本都找到其对应的另一个增强版本，而Batch内的其他$2N-2$个样本将充当负样本。优化的结果就是让同一个样本的两个增强版本在表示空间中具有尽可能大的一致性，同时和其他的Batch内负样本相距尽可能远。</p><h3 id=3-3-用于文本领域的数据增强方法探索>3.3 用于文本领域的数据增强方法探索</h3><p><img src=https://p0.meituan.net/travelcube/49a779ab260430f5e5d71c3d31385964174369.png class=lazyload data-srcset=https://p0.meituan.net/travelcube/49a779ab260430f5e5d71c3d31385964174369.png srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图4 四种高效的数据增强方法：Adversarial Attack、Token Shuffling、Cutoff、Dropout，均作用于Embedding层" referrerpolicy=no-referrer></p><p>图像领域可以方便地对样本进行变换，如旋转、翻转、裁剪、去色、模糊等等，从而得到对应的增强版本。然而，由于语言天然的复杂性，很难找到高效的、同时又保留语义不变的数据增强方法。一些显式生成增强样本的方法包括：</p><ul><li>回译：利用机器翻译模型，将文本翻译到另一个语言，再翻译回来。</li><li>CBERT$^\text&#123;[12][13]&#125;$ ：将文本的部分词替换成[MASK]，然后利用BERT去恢复对应的词，生成增强句子。</li><li>意译（Paraphrase）：利用训练好的Paraphrase生成模型生成同义句。</li></ul><p>然而这些方法一方面不一定能保证语义一致，另一方面每一次数据增强都需要做一次模型Inference，开销会很大。鉴于此，我们考虑了在Embedding层隐式生成增强样本的方法，如图4所示：</p><ul><li><strong>对抗攻击（Adversarial Attack）</strong>：这一方法通过梯度反传生成对抗扰动，将该扰动加到原本的Embedding矩阵上，就能得到增强后的样本。由于生成对抗扰动需要梯度反传，因此这一数据增强方法仅适用于有监督训练的场景。</li><li><strong>打乱词序（Token Shuffling）</strong>：这一方法扰乱输入样本的词序。由于Transformer结构没有“位置”的概念，模型对Token位置的感知全靠Embedding中的Position Ids得到。因此在实现上，我们只需要将Position Ids进行Shuffle即可。</li><li><strong>裁剪（Cutoff）</strong>：又可以进一步分为两种：<ul><li>Token Cutoff：随机选取Token，将对应Token的Embedding整行置为零。</li><li>Feature Cutoff：随机选取Embedding的Feature，将选取的Feature维度整列置为零。</li></ul></li><li><strong>Dropout</strong>：Embedding中的每一个元素都以一定概率置为零，与Cutoff不同的是，该方法并没有按行或者按列的约束。</li></ul><p>这四种方法均可以方便地通过对Embedding矩阵（或是BERT的Position Encoding）进行修改得到，因此相比显式生成增强文本的方法更为高效。</p><h3 id=3-4-进一步融合监督信号>3.4 进一步融合监督信号</h3><p>除了无监督训练以外，我们还提出了几种进一步融合监督信号的策略：</p><ol><li>联合训练（joint）：有监督的损失和无监督的损失通过加权联合训练模型。</li><li>先有监督再无监督（sup-unsup）：先使用有监督损失训练模型，再使用无监督的方法进行表示迁移。</li><li>联合训练再无监督（joint-unsup）：先使用联合损失训练模型，再使用无监督的方法进行表示迁移。</li></ol><h2 id=4-实验分析>4. 实验分析</h2><p>我们主要在文本语义匹配（Semantic Textual Similarity，STS）任务上进行了实验，包括七个数据集：STS12、STS13、STS14、STS15、STS16、STSb、SICK-R。其中STS12-16为SemEval2012 ～ 2016评测比赛放出的数据集；STSb为STS benchmark，来自于SemEval2017评测赛；SICK-R 表示 SICK-Relatedness，是SICK（Sentences Involving ComPositional Knowledge）数据集中的一个子任务，目标是推断两个句子时间的语义相关性（即Relatedness）。这些数据集中的样本均包含两个短文本text1和text2，以及人工标注的位于0～5之间的分数，代表text1和text2语义上的匹配程度（5表示最匹配，即“两句话表达的是同一个语义”；0表示最不匹配，即“两句话表达的语义完全不相关”）。下面给出了两条样本作为示例：</p><table><thead><tr><th>text1</th><th>text2</th><th>人工标注的语义相似度</th></tr></thead><tbody><tr><td>a man is cutting paper with a sword .</td><td>a woman is cutting a tomato .</td><td>0.6</td></tr><tr><td>a woman is dancing in the rain .</td><td>a woman dances in the rain out side .</td><td>5.0</td></tr></tbody></table><p>在测试时，我们根据此前的工作$^\text&#123;[1][2]&#125;$选择了斯皮尔曼相关系数（Spearman correlation）作为评测指标，它将用于衡量两组值（模型预测的余弦相似度和人工标注的语义相似度）之间的相关性，结果将位于[-1, 1]之间，仅当两组值完全正相关时取到1。对于每个数据集，我们将其测试样本全部融合计算该指标，并且报告了七个数据集的平均结果。考虑到简洁性，会在表格中报告乘以100倍的结果。</p><h3 id=4-1-无监督实验>4.1 无监督实验</h3><p><img src=https://p1.meituan.net/travelcube/6694e70738255bcf64065352fda2ea52209850.png class=lazyload data-srcset=https://p1.meituan.net/travelcube/6694e70738255bcf64065352fda2ea52209850.png srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图5 无监督设置下的实验结果" referrerpolicy=no-referrer></p><p>在无监督实验中，我们直接基于预训练的BERT在无标注的STS数据上进行Fine-tune。结果显示，我们的方法在完全一致的设置下大幅度超过之前的SOTA—BERT-flow，达到了8%的相对性能提升。</p><h3 id=4-2-有监督实验>4.2 有监督实验</h3><p><img src=https://p0.meituan.net/travelcube/4ac41de3fa204e1734db4831a84b9704299488.png class=lazyload data-srcset=https://p0.meituan.net/travelcube/4ac41de3fa204e1734db4831a84b9704299488.png srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图6 有监督设置下的实验结果" referrerpolicy=no-referrer></p><p>在有监督实验中，我们额外使用了来自SNLI和MNLI的训练数据，使用上面提到的融合额外监督信号的三种方法进行了实验。实验结果显示，我们的方法在“仅使用NLI有标注数据”和“使用NLI有标注数据 + STS无标注数据”的两种实验设置下均超过了基线。在三种融合监督信号的实验设置中，我们发现joint-unsup方法取得了最好的效果。</p><h3 id=4-3-不同的数据增强方法分析>4.3 不同的数据增强方法分析</h3><p><img src=https://p0.meituan.net/travelcube/5636106b8a90ab64399e4ce20986666d113422.png class=lazyload data-srcset=https://p0.meituan.net/travelcube/5636106b8a90ab64399e4ce20986666d113422.png srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图7 不同数据增强组合方法的性能" referrerpolicy=no-referrer></p><p>我们对不同的数据增强组合方法进行了消融分析，结果如图7所示。我们发现Token Shuffle和Feature Cutoff的组合取得了最优性能（72.74）。此外，就单种数据增强方法而言，Token Shuffle > Token Cutoff >> Feature Cutoff ≈ Dropout >> None。</p><h3 id=4-4-少样本设置下的实验分析>4.4 少样本设置下的实验分析</h3><p>我们进一步分析了数据量（无标注文本的数目）对效果的影响，结果如图8所示。结果显示，我们的方法仅需较少的样本就能近似达到全数据量的效果；同时，在样本量很少的情况下（如100条文本的情况下）仍相比于Baseline表现出不错的性能提升。</p><p><img src=https://p0.meituan.net/travelcube/ee5dadba429dd0fe669b42be496c5eb464154.png class=lazyload data-srcset=https://p0.meituan.net/travelcube/ee5dadba429dd0fe669b42be496c5eb464154.png srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图8 ConSERT在小样本情况下的性能" referrerpolicy=no-referrer></p><h3 id=4-5-temperature超参的实验分析>4.5 Temperature超参的实验分析</h3><p>在实验中，我们发现对比学习损失函数中的温度超参数（$\tau$）对于结果有很大影响。从图9的分析实验中可以看到，当$\tau$值在0.08到0.12之间时会得到最优结果。这个现象再次证明了BERT表示的塌缩问题，因为在句子表示都很接近的情况下，$\tau$过大会使句子间相似度更平滑，编码器很难学到知识。而$\tau$如果过小，任务就太过简单，所以需要调整到一个合适的范围内。</p><p><img src=https://p0.meituan.net/travelcube/b57d31e1c39d191e58a6cb5a9ff7bc1c66371.png class=lazyload data-srcset=https://p0.meituan.net/travelcube/b57d31e1c39d191e58a6cb5a9ff7bc1c66371.png srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图9 不同超参数$\tau$下的性能" referrerpolicy=no-referrer></p><h3 id=4-6-batch-size超参的实验分析>4.6 Batch size超参的实验分析</h3><p>在图像领域的对比学习中，Batch size会对结果有很大影响，因此我们也对比了不同Batch size下模型的表现。从图10可以看到两者基本是成正比的，但提升很有限。</p><p><img src=https://p0.meituan.net/travelcube/fe130fa4507ae264bcbbfc7fef8f1b4940127.png class=lazyload data-srcset=https://p0.meituan.net/travelcube/fe130fa4507ae264bcbbfc7fef8f1b4940127.png srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图10 不同Batch size下的性能" referrerpolicy=no-referrer></p><h2 id=5-总结>5. 总结</h2><p>在此工作中，我们分析了BERT句向量表示空间坍缩的原因，并提出了一种基于对比学习的句子表示迁移框架ConSERT。ConSERT在无监督Fine-tune和进一步融合监督信号的实验中均表现出了不错的性能；同时当收集到的样本数较少时，仍能有不错的性能提升，表现出较强的鲁棒性。</p><p>同时，在美团的业务场景下，有大量不同领域的短文本相关性计算需求，目前ConSERT已经在知识图谱构建、KBQA、搜索召回等业务场景使用。未来将会在美团更多业务上进行探索落地。目前，相关代码已经<a target=_blank rel=noopener href=https://github.com/yym6472/ConSERT>在GitHub上开源</a>，欢迎大家使用。</p><h2 id=参考文献>参考文献</h2><ul><li>[1] Reimers, Nils, and Iryna Gurevych. “Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks.” Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). 2019.</li><li>[2] Li, Bohan, et al. “On the Sentence Embeddings from Pre-trained Language Models.” Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). 2020.</li><li>[3] Gao, Jun, et al. “Representation Degeneration Problem in Training Natural Language Generation Models.” International Conference on Learning Representations. 2018.</li><li>[4] Wang, Lingxiao, et al. “Improving Neural Language Generation with Spectrum Control.” International Conference on Learning Representations. 2019.</li><li>[5] Conneau, Alexis, et al. “Supervised Learning of Universal Sentence Representations from Natural Language Inference Data.” Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. 2017.</li><li>[6] Cer, Daniel, et al. “Universal Sentence Encoder for English.” Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations. 2018.</li><li>[7] Wang, Shuohang, et al. “Cross-Thought for Sentence Encoder Pre-training.” Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). 2020.</li><li>[8] Yang, Ziyi, et al. “Universal Sentence Representation Learning with Conditional Masked Language Model.” arXiv preprint arXiv:2012.14388 (2020).</li><li>[9] Lee, Haejun, et al. “SLM: Learning a Discourse Language Representation with Sentence Unshuffling.” Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). 2020.</li><li>[10] Su, Jianlin, et al. “Whitening sentence representations for better semantics and faster retrieval.” arXiv preprint arXiv:2103.15316 (2021).</li><li>[11] Gao, Tianyu, Xingcheng Yao, and Danqi Chen. “SimCSE: Simple Contrastive Learning of Sentence Embeddings.” arXiv preprint arXiv:2104.08821 (2021).</li><li>[12] Wu, Xing, et al. “Conditional bert contextual augmentation.” International Conference on Computational Science. Springer, Cham, 2019.</li><li>[13] Zhou, Wangchunshu, et al. “BERT-based lexical substitution.” Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. 2019.</li><li>[14] He, Kaiming, et al. “Momentum contrast for unsupervised visual representation learning.” Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2020.</li><li>[15] Chen, Ting, et al. “A simple framework for contrastive learning of visual representations.” International conference on machine learning. PMLR, 2020.</li><li>[16] Zhang, Yan, et al. “An Unsupervised Sentence Embedding Method by Mutual Information Maximization.” Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). 2020.</li><li>[17] Fang, Hongchao, et al. “Cert: Contrastive self-supervised learning for language understanding.” arXiv preprint arXiv:2005.12766 (2020).</li><li>[18] Carlsson, Fredrik, et al. “Semantic re-tuning with contrastive tension.” International Conference on Learning Representations. 2021.</li><li>[19] Giorgi, John M., et al. “Declutr: Deep contrastive learning for unsupervised textual representations.” arXiv preprint arXiv:2006.03659 (2020).</li><li>[20] Wu, Zhuofeng, et al. “CLEAR: Contrastive Learning for Sentence Representation.” arXiv preprint arXiv:2012.15466(2020).</li></ul><h2 id=作者简介>作者简介</h2><ul><li>渊蒙、如寐、思睿、富峥、武威等，美团平台/搜索与NLP部。</li><li>徐蔚然，北京邮电大学人工智能学院，模式识别实验室，副教授，博士生导师。</li></ul></div><div class=footer><div class=copyright><blockquote><p>博客内容遵循 署名-非商业性使用-相同方式共享 4.0 国际 (CC BY-NC-SA 4.0) 协议</p><p>本文永久链接是：<a href=https://news.slqwq.cn/p/16b3.html>https://news.slqwq.cn/p/16b3.html</a></p></blockquote></div></div><div class=article-meta id=bottom><div class=new-meta-box><div class="new-meta-item date" itemprop=dateUpdated datetime=2021-07-11T00:43:41+00:00><a class=notlink><i class="fas fa-edit fa-fw" aria-hidden=true></i><p>更新于：2021年7月11日</p></a></div><div class="new-meta-item share -mob-share-list"><div class="-mob-share-list share-body"><a class=-mob-share-qq rel="external nofollow noopener noreferrer noopener" target=_blank href="http://connect.qq.com/widget/shareqq/index.html?url=https://news.slqwq.cn/p/16b3.html&title=ACL 2021｜美团提出基于对比学习的文本表示模型，效果相比BERT-flow提升8% - Hajeekn RSSHUB&pics=https://p0.meituan.net/travelcube/5f9553f85be65f3dbf8fd0dd1497c29f246638.png&summary="><img src=https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/logo/128/qq.png class=lazyload data-srcset=https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/logo/128/qq.png srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII="></a> <a class=-mob-share-qzone rel="external nofollow noopener noreferrer noopener" target=_blank href="https://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey?url=https://news.slqwq.cn/p/16b3.html&title=ACL 2021｜美团提出基于对比学习的文本表示模型，效果相比BERT-flow提升8% - Hajeekn RSSHUB&pics=https://p0.meituan.net/travelcube/5f9553f85be65f3dbf8fd0dd1497c29f246638.png&summary="><img src=https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/logo/128/qzone.png class=lazyload data-srcset=https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/logo/128/qzone.png srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII="></a> <a class=-mob-share-weibo rel="external nofollow noopener noreferrer noopener" target=_blank href="http://service.weibo.com/share/share.php?url=https://news.slqwq.cn/p/16b3.html&title=ACL 2021｜美团提出基于对比学习的文本表示模型，效果相比BERT-flow提升8% - Hajeekn RSSHUB&pics=https://p0.meituan.net/travelcube/5f9553f85be65f3dbf8fd0dd1497c29f246638.png&summary="><img src=https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/logo/128/weibo.png class=lazyload data-srcset=https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/logo/128/weibo.png srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII="></a></div></div></div></div><div class=prev-next><a class=prev href=/p/a879.html><p class=title><i class="fas fa-chevron-left" aria-hidden=true></i>虚幻5真牛</p><p class=content>原来虚幻5也是Metaverse。 PS5和Xbox Series已经发售半年了，除了一直买不到机器之外，我还是没有感觉到次世代的脉搏。 我印象中的次世代游戏，应该是一些上世代完全无法...</p></a><a class=next href=/p/9da2.html><p class=title>CVPR 2021 _ 基于Transformer的端到端视频实例分割方法<i class="fas fa-chevron-right" aria-hidden=true></i></p><p class=content>前言实例分割是计算机视觉中的基础问题之一。目前，静态图像中的实例分割业界已经进行了很多的研究，但是对视频的实例分割（Video Instance Segmentation，简称VIS）的...</p></a></div></article></div><aside class=l_side><section class="widget toc-wrapper shadow desktop mobile" id=toc-div><header><i class="fas fa-list fa-fw" aria-hidden=true></i> <span class=name>本文目录</span></header><div class=content><ol class=toc><li class="toc-item toc-level-2"><a class=toc-link href=#1-%E8%83%8C%E6%99%AF><span class=toc-text>1. 背景</span></a></li><li class="toc-item toc-level-2"><a class=toc-link href=#2-%E7%A0%94%E7%A9%B6%E7%8E%B0%E7%8A%B6%E5%92%8C%E7%9B%B8%E5%85%B3%E5%B7%A5%E4%BD%9C><span class=toc-text>2. 研究现状和相关工作</span></a><ol class=toc-child><li class="toc-item toc-level-3"><a class=toc-link href=#2-1-%E5%8F%A5%E5%AD%90%E8%A1%A8%E5%BE%81%E5%AD%A6%E4%B9%A0><span class=toc-text>2.1 句子表征学习</span></a></li><li class="toc-item toc-level-3"><a class=toc-link href=#2-2-%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0><span class=toc-text>2.2 对比学习</span></a></li></ol></li><li class="toc-item toc-level-2"><a class=toc-link href=#3-%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D><span class=toc-text>3. 模型介绍</span></a><ol class=toc-child><li class="toc-item toc-level-3"><a class=toc-link href=#3-1-%E9%97%AE%E9%A2%98%E5%AE%9A%E4%B9%89><span class=toc-text>3.1 问题定义</span></a></li><li class="toc-item toc-level-3"><a class=toc-link href=#3-2-%E5%9F%BA%E4%BA%8E%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%8F%A5%E5%AD%90%E8%A1%A8%E7%A4%BA%E8%BF%81%E7%A7%BB%E6%A1%86%E6%9E%B6><span class=toc-text>3.2 基于对比学习的句子表示迁移框架</span></a></li><li class="toc-item toc-level-3"><a class=toc-link href=#3-3-%E7%94%A8%E4%BA%8E%E6%96%87%E6%9C%AC%E9%A2%86%E5%9F%9F%E7%9A%84%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA%E6%96%B9%E6%B3%95%E6%8E%A2%E7%B4%A2><span class=toc-text>3.3 用于文本领域的数据增强方法探索</span></a></li><li class="toc-item toc-level-3"><a class=toc-link href=#3-4-%E8%BF%9B%E4%B8%80%E6%AD%A5%E8%9E%8D%E5%90%88%E7%9B%91%E7%9D%A3%E4%BF%A1%E5%8F%B7><span class=toc-text>3.4 进一步融合监督信号</span></a></li></ol></li><li class="toc-item toc-level-2"><a class=toc-link href=#4-%E5%AE%9E%E9%AA%8C%E5%88%86%E6%9E%90><span class=toc-text>4. 实验分析</span></a><ol class=toc-child><li class="toc-item toc-level-3"><a class=toc-link href=#4-1-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AE%9E%E9%AA%8C><span class=toc-text>4.1 无监督实验</span></a></li><li class="toc-item toc-level-3"><a class=toc-link href=#4-2-%E6%9C%89%E7%9B%91%E7%9D%A3%E5%AE%9E%E9%AA%8C><span class=toc-text>4.2 有监督实验</span></a></li><li class="toc-item toc-level-3"><a class=toc-link href=#4-3-%E4%B8%8D%E5%90%8C%E7%9A%84%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA%E6%96%B9%E6%B3%95%E5%88%86%E6%9E%90><span class=toc-text>4.3 不同的数据增强方法分析</span></a></li><li class="toc-item toc-level-3"><a class=toc-link href=#4-4-%E5%B0%91%E6%A0%B7%E6%9C%AC%E8%AE%BE%E7%BD%AE%E4%B8%8B%E7%9A%84%E5%AE%9E%E9%AA%8C%E5%88%86%E6%9E%90><span class=toc-text>4.4 少样本设置下的实验分析</span></a></li><li class="toc-item toc-level-3"><a class=toc-link href=#4-5-temperature%E8%B6%85%E5%8F%82%E7%9A%84%E5%AE%9E%E9%AA%8C%E5%88%86%E6%9E%90><span class=toc-text>4.5 Temperature超参的实验分析</span></a></li><li class="toc-item toc-level-3"><a class=toc-link href=#4-6-batch-size%E8%B6%85%E5%8F%82%E7%9A%84%E5%AE%9E%E9%AA%8C%E5%88%86%E6%9E%90><span class=toc-text>4.6 Batch size超参的实验分析</span></a></li></ol></li><li class="toc-item toc-level-2"><a class=toc-link href=#5-%E6%80%BB%E7%BB%93><span class=toc-text>5. 总结</span></a></li><li class="toc-item toc-level-2"><a class=toc-link href=#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE><span class=toc-text>参考文献</span></a></li><li class="toc-item toc-level-2"><a class=toc-link href=#%E4%BD%9C%E8%80%85%E7%AE%80%E4%BB%8B><span class=toc-text>作者简介</span></a></li></ol></div></section></aside><script>
  window.pdata={}
  pdata.ispage=true;
  pdata.postTitle="ACL 2021｜美团提出基于对比学习的文本表示模型，效果相比BERT-flow提升8%";
  pdata.commentPath="";
  pdata.commentPlaceholder="";
  // header 这里无论是否开启pjax都需要
  var l_header=document.getElementById("l_header");
  
  l_header.classList.add("show");
  
  
    // cover
    var cover_wrapper=document.querySelector('.cover-wrapper');
    
    cover_wrapper.id="none";
    cover_wrapper.style.display="none";
    
  
</script></div><footer class="footer clearfix"><br><br><div class=aplayer-container></div><br><div class=social-wrapper></div><div><p>博客内容遵循 <a target=_blank rel=noopener href=https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh>署名-非商业性使用-相同方式共享 4.0 国际 (CC BY-NC-SA 4.0) 协议</a></p></div><div><p><span id=lc-sv>本站总访问量为<span id=number><i class="fas fa-circle-notch fa-spin fa-fw" aria-hidden=true></i></span> 次</span> <span id=lc-uv>访客数为<span id=number><i class="fas fa-circle-notch fa-spin fa-fw" aria-hidden=true></i></span> 人</span></p></div>本站使用 <a href=https://github.com/volantis-x/hexo-theme-volantis/tree/4.3.1 target=_blank class=codename>Volantis</a> 作为主题<div class=copyright><p><a href="/">Copyright © 2017-2020 XXX</a></p></div></footer><a id=s-top class="fas fa-arrow-up fa-fw" href=javascript:void(0)></a></div></div><div><script>
/************这个文件存放不需要重载的全局变量和全局函数*********/
window.volantis={};
window.volantis.loadcss=document.getElementById("loadcss");
/******************** Pjax ********************************/
function VPjax(){
	this.list=[] // 存放回调函数
	this.start=()=>{
	  for(var i=0;i<this.list.length;i++){
		this.list[i].run();
	  }
	}
	this.push=(fn,name)=>{
		var f=new PjaxItem(fn,name);
		this.list.push(f);
	}
	// 构造一个可以run的对象
	function PjaxItem(fn,name){
		// 函数名称
		this.name = name || fn.name
		// run方法
		this.run=()=>{
			fn()
		}
	}
}
volantis.pjax={}
volantis.pjax.method={
	complete: new VPjax(),
	error: new VPjax(),
	send: new VPjax()
}
volantis.pjax={
	...volantis.pjax,
	push: volantis.pjax.method.complete.push,
	error: volantis.pjax.method.error.push,
	send: volantis.pjax.method.send.push
}
/********************脚本懒加载函数********************************/
// 已经加入了setTimeout
function loadScript(src, cb) {
	setTimeout(function() {
		var HEAD = document.getElementsByTagName('head')[0] || document.documentElement;
		var script = document.createElement('script');
		script.setAttribute('type','text/javascript');
		if (cb) script.onload = cb;
		script.setAttribute('src', src);
		HEAD.appendChild(script);
	});
}
//https://github.com/filamentgroup/loadCSS
var loadCSS = function( href, before, media, attributes ){
	var doc = window.document;
	var ss = doc.createElement( "link" );
	var ref;
	if( before ){
		ref = before;
	}
	else {
		var refs = ( doc.body || doc.getElementsByTagName( "head" )[ 0 ] ).childNodes;
		ref = refs[ refs.length - 1];
	}
	var sheets = doc.styleSheets;
	if( attributes ){
		for( var attributeName in attributes ){
			if( attributes.hasOwnProperty( attributeName ) ){
				ss.setAttribute( attributeName, attributes[attributeName] );
			}
		}
	}
	ss.rel = "stylesheet";
	ss.href = href;
	ss.media = "only x";
	function ready( cb ){
		if( doc.body ){
			return cb();
		}
		setTimeout(function(){
			ready( cb );
		});
	}
	ready( function(){
		ref.parentNode.insertBefore( ss, ( before ? ref : ref.nextSibling ) );
	});
	var onloadcssdefined = function( cb ){
		var resolvedHref = ss.href;
		var i = sheets.length;
		while( i-- ){
			if( sheets[ i ].href === resolvedHref ){
				return cb();
			}
		}
		setTimeout(function() {
			onloadcssdefined( cb );
		});
	};
	function loadCB(){
		if( ss.addEventListener ){
			ss.removeEventListener( "load", loadCB );
		}
		ss.media = media || "all";
	}
	if( ss.addEventListener ){
		ss.addEventListener( "load", loadCB);
	}
	ss.onloadcssdefined = onloadcssdefined;
	onloadcssdefined( loadCB );
	return ss;
};
</script><script>
  
  loadCSS("https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.14/css/all.min.css", window.volantis.loadcss);
  
  
  
  
</script><script src=https://cdn.jsdelivr.net/npm/jquery@3.5/dist/jquery.min.js></script><script>
  function pjax_fancybox() {
    $(".md .gallery").find("img").each(function () { //渲染 fancybox
      var element = document.createElement("a"); // a 标签
      $(element).attr("class", "fancybox");
      $(element).attr("pjax-fancybox", "");  // 过滤 pjax
      $(element).attr("href", $(this).attr("src"));
      if ($(this).attr("data-original")) {
        $(element).attr("href", $(this).attr("data-original"));
      }
      $(element).attr("data-fancybox", "images");
      var caption = "";   // 描述信息
      if ($(this).attr('alt')) {  // 判断当前页面是否存在描述信息
        $(element).attr('data-caption', $(this).attr('alt'));
        caption = $(this).attr('alt');
      }
      var div = document.createElement("div");
      $(div).addClass("fancybox");
      $(this).wrap(div); // 最外层套 div ，其实主要作用还是 class 样式
      var span = document.createElement("span");
      $(span).addClass("image-caption");
      $(span).text(caption); // 加描述
      $(this).after(span);  // 再套一层描述
      $(this).wrap(element);  // 最后套 a 标签
    })
    $(".md .gallery").find("img").fancybox({
      selector: '[data-fancybox="images"]',
      hash: false,
      loop: false,
      closeClick: true,
      helpers: {
        overlay: {closeClick: true}
      },
      buttons: [
        "zoom",
        "close"
      ]
    });
  };
  function SCload_fancybox() {
    if ($(".md .gallery").find("img").length == 0) return;
    loadCSS("https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css", document.getElementById("loadcss"));
    loadScript('https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js', pjax_fancybox)
  };
  $(function () {
    SCload_fancybox();
  });
  function Pjax_SCload_fancybox(){
	if (typeof $.fancybox == "undefined") {
	 SCload_fancybox();
    } else {
	 pjax_fancybox();
    }
  }
  volantis.pjax.push(Pjax_SCload_fancybox)
  volantis.pjax.send(()=>{
      if (typeof $.fancybox != "undefined") {
        $.fancybox.close();    // 关闭弹窗
      }
  },'fancybox')
</script><script>
  function loadIssuesJS() {
    if ($(".md").find(".issues-api").length == 0) return;
	
	  loadScript('/js/issues.js');
	
  };
  $(function () {
    loadIssuesJS();
  });
  volantis.pjax.push(()=>{
	if (typeof IssuesAPI == "undefined") {
	  loadIssuesJS();
	}
  },"IssuesJS")
</script><script defer src=https://cdn.jsdelivr.net/npm/vanilla-lazyload@17.1.0/dist/lazyload.min.js></script><script>
  // https://www.npmjs.com/package/vanilla-lazyload
  // Set the options globally
  // to make LazyLoad self-initialize
  window.lazyLoadOptions = {
    elements_selector: ".lazyload",
    threshold: 0
  };
  // Listen to the initialization event
  // and get the instance of LazyLoad
  window.addEventListener(
    "LazyLoad::Initialized",
    function (event) {
      window.lazyLoadInstance = event.detail.instance;
    },
    false
  );
  document.addEventListener('DOMContentLoaded', function () {
    lazyLoadInstance.update();
  });
  document.addEventListener('pjax:complete', function () {
    lazyLoadInstance.update();
  });
</script><script>
  window.FPConfig = {
	delay: 0,
	ignoreKeywords: [],
	maxRPS: 5,
	hoverDelay: 25
  };
</script><script defer src=https://cdn.jsdelivr.net/gh/gijo-varghese/flying-pages@2.1.2/flying-pages.min.js></script><script src=/js/valine.js></script><script>
  function emoji(path, idx, ext) {
    return path + "/" + path + "-" + idx + "." + ext;
  }
  var emojiMaps = {};
  for (var i = 1; i <= 54; i++) {
    emojiMaps['tieba-' + i] = emoji('tieba', i, 'png');
  }
  for (var i = 1; i <= 101; i++) {
    emojiMaps['qq-' + i] = emoji('qq', i, 'gif');
  }
  for (var i = 1; i <= 116; i++) {
    emojiMaps['aru-' + i] = emoji('aru', i, 'gif');
  }
  for (var i = 1; i <= 125; i++) {
    emojiMaps['twemoji-' + i] = emoji('twemoji', i, 'png');
  }
  for (var i = 1; i <= 4; i++) {
    emojiMaps['weibo-' + i] = emoji('weibo', i, 'png');
  }
  function pjax_valine() {
    if(!document.querySelectorAll("#valine_container")[0])return;
    let pagePlaceholder = pdata.commentPlaceholder || "快来评论吧~";
    let path = pdata.commentPath;
    if (path.length == 0) {
      let defaultPath = '';
      path = defaultPath || decodeURI(window.location.pathname);
    }
    var valine = new Valine();
    valine.init(Object.assign({"path":null,"placeholder":"快来评论吧~","appId":null,"appKey":null,"meta":["nick","mail","link"],"requiredFields":["nick","mail"],"enableQQ":true,"recordIP":false,"avatar":"robohash","pageSize":10,"lang":"zh-cn","highlight":true,"mathJax":false}, {
      el: '#valine_container',
      path: path,
      placeholder: pagePlaceholder,
      emojiCDN: 'https://cdn.jsdelivr.net/gh/volantis-x/cdn-emoji/valine/',
      emojiMaps: emojiMaps,
    }))
  }
  $(function () {
    pjax_valine();
  });
  volantis.pjax.push(pjax_valine);
</script><script src=/js/app.js></script><script>
const SearchServiceimagePath="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@master/img/";
const ROOT =  ("/" || "/").endsWith('/') ? ("/" || "/") : ("//" || "/" );

$('.input.u-search-input').one('focus',function(){
	
		loadScript('/js/search/hexo.js',setSearchService);
	
})

function listenSearch(){
  
    customSearch = new HexoSearch({
      imagePath: SearchServiceimagePath
    });
  
}
function setSearchService() {
	listenSearch();
	
}
</script><script defer>

  const LCCounter = {
    app_id: 'u9j57bwJod4EDmXWdxrwuqQT-MdYXbMMI',
    app_key: 'jfHtEKVE24j0IVCGHbvuFClp',
    custom_api_server: '',

    // 查询存储的记录
    getRecord(Counter, url, title) {
      return new Promise(function (resolve, reject) {
        Counter('get', '/classes/Counter?where=' + encodeURIComponent(JSON.stringify({url})))
          .then(resp => resp.json())
          .then(({results, code, error}) => {
            if (code === 401) {
              throw error;
            }
            if (results && results.length > 0) {
              var record = results[0];
              resolve(record);
            } else {
              Counter('post', '/classes/Counter', {url, title: title, times: 0})
                .then(resp => resp.json())
                .then((record, error) => {
                  if (error) {
                    throw error;
                  }
                  resolve(record);
                }).catch(error => {
                console.error('Failed to create', error);
                reject(error);
              });
            }
          }).catch((error) => {
          console.error('LeanCloud Counter Error:', error);
          reject(error);
        });
      })
    },

    // 发起自增请求
    increment(Counter, incrArr) {
      return new Promise(function (resolve, reject) {
        Counter('post', '/batch', {
          "requests": incrArr
        }).then((res) => {
          res = res.json();
          if (res.error) {
            throw res.error;
          }
          resolve(res);
        }).catch((error) => {
          console.error('Failed to save visitor count', error);
          reject(error);
        });
      });
    },

    // 构建自增请求体
    buildIncrement(objectId) {
      return {
        "method": "PUT",
        "path": `/1.1/classes/Counter/${ objectId }`,
        "body": {
          "times": {
            '__op': 'Increment',
            'amount': 1
          }
        }
      }
    },

    // 校验是否为有效的 UV
    validUV() {
      var key = 'LeanCloudUVTimestamp';
      var flag = localStorage.getItem(key);
      if (flag) {
        // 距离标记小于 24 小时则不计为 UV
        if (new Date().getTime() - parseInt(flag) <= 86400000) {
          return false;
        }
      }
      localStorage.setItem(key, new Date().getTime().toString());
      return true;
    },

    addCount(Counter) {
      var enableIncr = '' === 'true' && window.location.hostname !== 'localhost';
      enableIncr = true;
      var getterArr = [];
      var incrArr = [];
      // 请求 PV 并自增
      var pvCtn = document.querySelector('#lc-sv');
      if (pvCtn || enableIncr) {
        var pvGetter = this.getRecord(Counter, 'https://news.slqwq.cn' + '/#lc-sv', 'Visits').then((record) => {
          incrArr.push(this.buildIncrement(record.objectId))
          var eles = document.querySelectorAll('#lc-sv #number');
          if (eles.length > 0) {
            eles.forEach((el,index,array)=>{
              el.innerText = record.times + 1;
              if (pvCtn) {
                pvCtn.style.display = 'inline';
              }
            })
          }
        });
        getterArr.push(pvGetter);
      }

      // 请求 UV 并自增
      var uvCtn = document.querySelector('#lc-uv');
      if (uvCtn || enableIncr) {
        var uvGetter = this.getRecord(Counter, 'https://news.slqwq.cn' + '/#lc-uv', 'Visitors').then((record) => {
          var vuv = this.validUV();
          vuv && incrArr.push(this.buildIncrement(record.objectId))
          var eles = document.querySelectorAll('#lc-uv #number');
          if (eles.length > 0) {
            eles.forEach((el,index,array)=>{
              el.innerText = record.times + (vuv ? 1 : 0);
              if (uvCtn) {
                uvCtn.style.display = 'inline';
              }
            })
          }
        });
        getterArr.push(uvGetter);
      }

      // 请求文章的浏览数，如果是当前页面就自增
      var allPV = document.querySelectorAll('#lc-pv');
      if (allPV.length > 0 || enableIncr) {
        for (i = 0; i < allPV.length; i++) {
          let pv = allPV[i];
          let title = pv.getAttribute('data-title');
          var url = 'https://news.slqwq.cn' + pv.getAttribute('data-path');
          if (url) {
            var viewGetter = this.getRecord(Counter, url, title).then((record) => {
              // 是当前页面就自增
              let curPath = window.location.pathname;
              if (curPath.includes('index.html')) {
                curPath = curPath.substring(0, curPath.lastIndexOf('index.html'));
              }
              if (pv.getAttribute('data-path') == curPath) {
                incrArr.push(this.buildIncrement(record.objectId));
              }
              if (pv) {
                var ele = pv.querySelector('#lc-pv #number');
                if (ele) {
                  if (pv.getAttribute('data-path') == curPath) {
                    ele.innerText = (record.times || 0) + 1;
                  } else {
                    ele.innerText = record.times || 0;
                  }
                  pv.style.display = 'inline';
                }
              }
            });
            getterArr.push(viewGetter);
          }
        }
      }

      // 如果启动计数自增，批量发起自增请求
      if (enableIncr) {
        Promise.all(getterArr).then(() => {
          incrArr.length > 0 && this.increment(Counter, incrArr);
        })
      }

    },


    fetchData(api_server) {
      var Counter = (method, url, data) => {
        return fetch(`${ api_server }/1.1${ url }`, {
          method,
          headers: {
            'X-LC-Id': this.app_id,
            'X-LC-Key': this.app_key,
            'Content-Type': 'application/json',
          },
          body: JSON.stringify(data)
        });
      };
      this.addCount(Counter);
    },

    refreshCounter() {
      var api_server = this.app_id.slice(-9) !== '-MdYXbMMI' ? this.custom_api_server : `https://${ this.app_id.slice(0, 8).toLowerCase() }.api.lncldglobal.com`;
      if (api_server) {
        this.fetchData(api_server);
      } else {
        fetch('https://app-router.leancloud.cn/2/route?appId=' + this.app_id)
          .then(resp => resp.json())
          .then(({api_server}) => {
            this.fetchData('https://' + api_server);
          });
      }
    }

  };

  LCCounter.refreshCounter();

  document.addEventListener('pjax:complete', function () {
    LCCounter.refreshCounter();
  });
</script><script>
const rootElement = document.documentElement;
const darkModeStorageKey = "user-color-scheme";
const rootElementDarkModeAttributeName = "data-user-color-scheme";

const setLS = (k, v) => {
    localStorage.setItem(k, v);
};

const removeLS = (k) => {
    localStorage.removeItem(k);
};

const getLS = (k) => {
    return localStorage.getItem(k);
};

const getModeFromCSSMediaQuery = () => {
  return window.matchMedia("(prefers-color-scheme: dark)").matches
    ? "dark"
    : "light";
};

const resetRootDarkModeAttributeAndLS = () => {
  rootElement.removeAttribute(rootElementDarkModeAttributeName);
  removeLS(darkModeStorageKey);
};

const validColorModeKeys = {
  dark: true,
  light: true,
};

const applyCustomDarkModeSettings = (mode) => {
  const currentSetting = mode || getLS(darkModeStorageKey);

  if (currentSetting === getModeFromCSSMediaQuery()) {
    resetRootDarkModeAttributeAndLS();
  } else if (validColorModeKeys[currentSetting]) {
    rootElement.setAttribute(rootElementDarkModeAttributeName, currentSetting);
  } else {
    resetRootDarkModeAttributeAndLS();
  }
};

const invertDarkModeObj = {
  dark: "light",
  light: "dark",
};

/**
 * get target mode
 */
const toggleCustomDarkMode = () => {
  let currentSetting = getLS(darkModeStorageKey);

  if (validColorModeKeys[currentSetting]) {
    currentSetting = invertDarkModeObj[currentSetting];
  } else if (currentSetting === null) {
    currentSetting = invertDarkModeObj[getModeFromCSSMediaQuery()];
  } else {
    return;
  }
  setLS(darkModeStorageKey, currentSetting);
  return currentSetting;
};

/**
 * bind click event for toggle button
 */
var btn=$("#wrapper .toggle-mode-btn,#rightmenu-wrapper .toggle-mode-btn");
function bindToggleButton() {
    btn.on('click',(e) => {
      const mode = toggleCustomDarkMode();
      applyCustomDarkModeSettings(mode);
    });
}

applyCustomDarkModeSettings();
document.addEventListener("DOMContentLoaded", bindToggleButton);
volantis.pjax.push(bindToggleButton);
volantis.pjax.send(()=>{
	btn.unbind('click');
},'toggle-mode-btn-unbind');
</script><script>
function listennSidebarTOC() {
  const navItems = document.querySelectorAll(".toc li");
  if (!navItems.length) return;
  const sections = [...navItems].map((element) => {
    const link = element.querySelector(".toc-link");
    const target = document.getElementById(
      decodeURI(link.getAttribute("href")).replace("#", "")
    );
    link.addEventListener("click", (event) => {
      event.preventDefault();
      window.scrollTo({
		top: target.offsetTop + 100,
		
		behavior: "smooth"
		
	  });
    });
    return target;
  });

  function activateNavByIndex(target) {
    if (target.classList.contains("active-current")) return;

    document.querySelectorAll(".toc .active").forEach((element) => {
      element.classList.remove("active", "active-current");
    });
    target.classList.add("active", "active-current");
    let parent = target.parentNode;
    while (!parent.matches(".toc")) {
      if (parent.matches("li")) parent.classList.add("active");
      parent = parent.parentNode;
    }
  }

  function findIndex(entries) {
    let index = 0;
    let entry = entries[index];
    if (entry.boundingClientRect.top > 0) {
      index = sections.indexOf(entry.target);
      return index === 0 ? 0 : index - 1;
    }
    for (; index < entries.length; index++) {
      if (entries[index].boundingClientRect.top <= 0) {
        entry = entries[index];
      } else {
        return sections.indexOf(entry.target);
      }
    }
    return sections.indexOf(entry.target);
  }

  function createIntersectionObserver(marginTop) {
    marginTop = Math.floor(marginTop + 10000);
    let intersectionObserver = new IntersectionObserver(
      (entries, observe) => {
        let scrollHeight = document.documentElement.scrollHeight + 100;
        if (scrollHeight > marginTop) {
          observe.disconnect();
          createIntersectionObserver(scrollHeight);
          return;
        }
        let index = findIndex(entries);
        activateNavByIndex(navItems[index]);
      },
      {
        rootMargin: marginTop + "px 0px -100% 0px",
        threshold: 0,
      }
    );
    sections.forEach((element) => {
      element && intersectionObserver.observe(element);
    });
  }
  createIntersectionObserver(document.documentElement.scrollHeight);
}

document.addEventListener("DOMContentLoaded", listennSidebarTOC);
document.addEventListener("pjax:success", listennSidebarTOC);
</script><script src=https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.min.js></script><script>
    var pjax;
    document.addEventListener('DOMContentLoaded', function () {
      pjax = new Pjax({
        elements: 'a[href]:not([href^="#"]):not([href="javascript:void(0)"]):not([pjax-fancybox])',
        selectors: [
          "title",
          
          "#pjax-container",
          "#pjax-header-nav-list"
        ],
        cacheBust: false,   // url 地址追加时间戳，用以避免浏览器缓存
        timeout: 5000
      });
    });

    document.addEventListener('pjax:send', function (e) {
      //window.stop(); // 相当于点击了浏览器的停止按钮

      try {
        var currentUrl = window.location.pathname;
        var targetUrl = e.triggerElement.href;
        var banUrl = [""];
        if (banUrl[0] != "") {
          banUrl.forEach(item => {
            if(currentUrl.indexOf(item) != -1 || targetUrl.indexOf(item) != -1) {
              window.location.href = targetUrl;
            }
          });
        }
      } catch (error) {}

      window.subData = null; // 移除标题（用于一二级导航栏切换处）

      volantis.$switcher.removeClass('active'); // 关闭移动端激活的搜索框
      volantis.$header.removeClass('z_search-open'); // 关闭移动端激活的搜索框
      volantis.$wrapper.removeClass('sub'); // 跳转页面时关闭二级导航

      // 解绑事件 避免重复监听
      volantis.$topBtn.unbind('click');
      $('.menu a').unbind('click');
      $(window).unbind('resize');
      $(window).unbind('scroll');
      $(document).unbind('scroll');
      $(document).unbind('click');
      $('body').unbind('click');
	  // 使用 volantis.pjax.send 方法传入pjax:send回调函数 参见layout/_partial/scripts/global.ejs
	  volantis.pjax.method.send.start();
    });

    document.addEventListener('pjax:complete', function () {
      $('.nav-main').find('.list-v').not('.menu-phone').removeAttr("style",""); // 移除小尾巴的移除
      $('.menu-phone.list-v').removeAttr("style",""); // 移除小尾巴的移除
      $('script[data-pjax], .pjax-reload script').each(function () {
        $(this).parent().append($(this).remove());
      });
      try{
		// 使用 volantis.pjax.push 方法传入重载函数 参见layout/_partial/scripts/global.ejs
		volantis.pjax.method.complete.start();
      } catch (e) {
        console.log(e);
      }
    });

    document.addEventListener('pjax:error', function (e) {
	  // 使用 volantis.pjax.error 方法传入pjax:error回调函数 参见layout/_partial/scripts/global.ejs
	  volantis.pjax.method.error.start();
      window.location.href = e.triggerElement.href;
    });
</script></div></body></html>