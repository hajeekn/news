<!DOCTYPE html><html lang=zh-CN><head hexo-theme=https://github.com/volantis-x/hexo-theme-volantis/tree/4.3.1><meta charset=utf-8><meta http-equiv=x-dns-prefetch-control content=on><link rel=dns-prefetch href=https://cdn.jsdelivr.net><link rel=preconnect href=https://cdn.jsdelivr.net crossorigin><meta name=renderer content=webkit><meta name=force-rendering content=webkit><meta http-equiv=X-UA-Compatible content="IE=Edge,chrome=1"><meta name=HandheldFriendly content=True><meta name=apple-mobile-web-app-capable content=yes><meta name=viewport content="width=device-width, initial-scale=1, maximum-scale=1"><link rel=preload href=/css/first.css as=style><title>CVPR 2021 _ 基于Transformer的端到端视频实例分割方法 - Hajeekn RSSHUB</title><link rel=alternate href=/atom.xml title="Hajeekn RSSHUB" type=application/atom+xml><meta name=referrer content=no-referrer><link rel=stylesheet href=/css/diy.css><link rel=stylesheet href=/css/first.css><link rel=stylesheet href=/css/style.css media=print onload="this.media='all';this.onload=null"><noscript><link rel=stylesheet href=/css/style.css></noscript><script id=loadcss></script><script>
if (/*@cc_on!@*/false || (!!window.MSInputMethodContext && !!document.documentMode))
    document.write(
	'<style>'+
		'html{'+
			'overflow-x: hidden !important;'+
			'overflow-y: hidden !important;'+
		'}'+
		'.kill-ie{'+
			'text-align:center;'+
			'height: 100%;'+
			'margin-top: 15%;'+
			'margin-bottom: 5500%;'+
		'}'+
	'</style>'+
    '<div class="kill-ie">'+
        '<h1><b>抱歉，您的浏览器无法访问本站</b></h1>'+
        '<h3>微软已经于2016年终止了对 Internet Explorer (IE) 10 及更早版本的支持，<br/>'+
        '继续使用存在极大的安全隐患，请使用当代主流的浏览器进行访问。</h3><br/>'+
        '<a target="_blank" rel="noopener" href="https://www.microsoft.com/zh-cn/WindowsForBusiness/End-of-IE-support"><strong>了解详情 ></strong></a>'+
    '</div>');
</script><noscript><style>
		html{
			overflow-x: hidden !important;
			overflow-y: hidden !important;
		}
		.kill-noscript{
			text-align:center;
			height: 100%;
			margin-top: 15%;
			margin-bottom: 5500%;
		}
	</style><div class=kill-noscript><h1><b>抱歉，您的浏览器无法访问本站</b></h1><h3>本页面需要浏览器支持（启用）JavaScript</h3><br><a target=_blank rel=noopener href="https://www.baidu.com/s?wd=启用JavaScript"><strong>了解详情 ></strong></a></div></noscript></head><body><header id=l_header class="l_header always shadow blur show"><div class=container><div id=wrapper><div class=nav-sub><p class=title></p><ul class="switcher nav-list-h m-phone" id=pjax-header-nav-list><li><a id=s-comment class="fas fa-comments fa-fw" target=_self href=javascript:void(0)></a></li><li><a id=s-toc class="s-toc fas fa-list fa-fw" target=_self href=javascript:void(0)></a></li></ul></div><div class=nav-main><a class="title flat-box" target=_self href="/"><img no-lazy class=logo src=https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/blog/Logo-NavBar@3x.png></a><div class="menu navigation"><ul class="nav-list-h m-pc"><li><a class="menuitem flat-box faa-parent animated-hover" href="/" id=home><i class="fas fa-home fa-fw fa-fw"></i> 主页</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/categories/%E5%8D%9A%E5%AE%A2/" id=categoriesE58D9AE5AEA2><i class="fas fa-rss fa-fw"></i> 博客订阅</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/categories/%E6%96%B0%E5%AA%92%E4%BD%93/" id=categoriesE696B0E5AA92E4BD93><i class="fas fa-podcast fa-fw fa-fw"></i> 新媒体</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/categories/%E4%BA%8C%E6%AC%A1%E5%85%83/" id=categoriesE4BA8CE6ACA1E58583><i class="fas fa-heart fa-fw fa-fw"></i> 二次元</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/categories/%E6%B8%B8%E6%88%8F/" id=categoriesE6B8B8E6888F><i class="fa fa-gamepad fa-fw fa-fw"></i> 游戏</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/categories/%E5%9B%BE%E7%89%87/" id=categoriesE59BBEE78987><i class="fas fa-puzzle-piece fa-fw fa-fw"></i> 图片</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/categories/%E8%AE%BE%E8%AE%A1/" id=categoriesE8AEBEE8AEA1><i class="fas fa-magic fa-fw fa-fw"></i> 设计</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/categories/%E7%BC%96%E7%A8%8B/" id=categoriesE7BC96E7A88B><i class="fas fa-code fa-fw fa-fw"></i> 编程</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/categories/%E9%87%91%E8%9E%8D/" id=categoriesE98791E89E8D><i class="fas fa-key fa-fw fa-fw"></i> 金融</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/categories/%E7%A4%BE%E4%BA%A4%E5%AA%92%E4%BD%93/" id=categoriesE7A4BEE4BAA4E5AA92E4BD93><i class="fas fa-users fa-fw fa-fw"></i> 社交媒体</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/categories/%E9%98%85%E8%AF%BB/" id=categoriesE99885E8AFBB><i class="fas fa-book fa-fw fa-fw"></i> 阅读</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/categories/%E5%AD%A6%E4%B9%A0/" id=categoriesE5ADA6E4B9A0><i class="fas fa-graduation-cap fa-fw fa-fw"></i> 学习</a></li></ul></div><div class=m_search><form name=searchform class="form u-search-form"><i class="icon fas fa-search fa-fw"></i> <input type=text class="input u-search-input" placeholder=Search...></form></div><ul class="switcher nav-list-h m-phone"><li><a class="s-search fas fa-search fa-fw" target=_self href=javascript:void(0)></a></li><li><a class="s-menu fas fa-bars fa-fw" target=_self href=javascript:void(0)></a><ul class="menu-phone list-v navigation white-box"><li><a class="menuitem flat-box faa-parent animated-hover" href="/" id=home><i class="fas fa-home fa-fw fa-fw"></i> 主页</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/categories/%E5%8D%9A%E5%AE%A2/" id=categoriesE58D9AE5AEA2><i class="fas fa-rss fa-fw"></i> 博客订阅</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/categories/%E6%96%B0%E5%AA%92%E4%BD%93/" id=categoriesE696B0E5AA92E4BD93><i class="fas fa-podcast fa-fw fa-fw"></i> 新媒体</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/categories/%E4%BA%8C%E6%AC%A1%E5%85%83/" id=categoriesE4BA8CE6ACA1E58583><i class="fas fa-heart fa-fw fa-fw"></i> 二次元</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/categories/%E6%B8%B8%E6%88%8F/" id=categoriesE6B8B8E6888F><i class="fa fa-gamepad fa-fw fa-fw"></i> 游戏</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/categories/%E5%9B%BE%E7%89%87/" id=categoriesE59BBEE78987><i class="fas fa-puzzle-piece fa-fw fa-fw"></i> 图片</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/categories/%E8%AE%BE%E8%AE%A1/" id=categoriesE8AEBEE8AEA1><i class="fas fa-magic fa-fw fa-fw"></i> 设计</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/categories/%E7%BC%96%E7%A8%8B/" id=categoriesE7BC96E7A88B><i class="fas fa-code fa-fw fa-fw"></i> 编程</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/categories/%E9%87%91%E8%9E%8D/" id=categoriesE98791E89E8D><i class="fas fa-key fa-fw fa-fw"></i> 金融</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/categories/%E7%A4%BE%E4%BA%A4%E5%AA%92%E4%BD%93/" id=categoriesE7A4BEE4BAA4E5AA92E4BD93><i class="fas fa-users fa-fw fa-fw"></i> 社交媒体</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/categories/%E9%98%85%E8%AF%BB/" id=categoriesE99885E8AFBB><i class="fas fa-book fa-fw fa-fw"></i> 阅读</a></li><li><a class="menuitem flat-box faa-parent animated-hover" href="/categories/%E5%AD%A6%E4%B9%A0/" id=categoriesE5ADA6E4B9A0><i class="fas fa-graduation-cap fa-fw fa-fw"></i> 学习</a></li></ul></li></ul></div></div></div></header><div id=l_body><div id=l_cover><div id=full class="cover-wrapper post dock" style="display: none;"><div class="cover-bg lazyload placeholder" data-bg="https://uploadbeta.com/api/pictures/random/?key=BingEverydayWallpaperPicture"></div><div class=cover-body><div class=top><p class=title>Volantis</p></div><div class=bottom><div class="menu navigation"><div class=list-h><a href="/v4/getting-started/" id=v4getting-started><img src=https://cdn.jsdelivr.net/gh/twitter/twemoji@13.0/assets/svg/1f5c3.svg><p>文档</p></a> <a href="/faqs/" id=faqs><img src=https://cdn.jsdelivr.net/gh/twitter/twemoji@13.0/assets/svg/1f516.svg><p>帮助</p></a> <a href="/examples/" id=examples><img src=https://cdn.jsdelivr.net/gh/twitter/twemoji@13.0/assets/svg/1f396.svg><p>示例</p></a> <a href="/contributors/" id=contributors><img src=https://cdn.jsdelivr.net/gh/twitter/twemoji@13.0/assets/svg/1f389.svg><p>社区</p></a> <a href="/archives/" id=archives><img src=https://cdn.jsdelivr.net/gh/twitter/twemoji@13.0/assets/svg/1f4f0.svg><p>博客</p></a> <a target=_blank rel=noopener href="https://github.com/volantis-x/hexo-theme-volantis/" id=https:githubcomvolantis-xhexo-theme-volantis><img src=https://cdn.jsdelivr.net/gh/twitter/twemoji@13.0/assets/svg/1f9ec.svg><p>源码</p></a></div></div></div></div><div id=scroll-down style="display: none;"><i class="fa fa-chevron-down scroll-down-effects"></i></div></div></div><div id=safearea><div class=body-wrapper id=pjax-container><div class=l_main><article class="article post white-box reveal md shadow article-type-post" id=post itemscope itemprop=blogPost><div class=headimg-div><a class=headimg-a><img class=headimg src=https://p0.meituan.net/travelcube/c69baf94f90d6f7020d4272a10930078554707.png></a></div><div class=article-meta id=top><a title="CVPR 2021 _ 基于Transformer的端到端视频实例分割方法" href=/p/9da2.html><img class=thumbnail src=https://p0.meituan.net/travelcube/c69baf94f90d6f7020d4272a10930078554707.png></a><h1 class=title>CVPR 2021 _ 基于Transformer的端到端视频实例分割方法</h1><div class=new-meta-box><div class="new-meta-item author"><a class=author target=_blank href="https://docs.rsshub.app/" rel="nofollow noopener"><img no-lazy src=https://i.loli.net/2019/04/23/5cbeb7e41414c.png><p>RSSHub</p></a></div><div class="new-meta-item category"><a class=notlink><i class="fas fa-folder-open fa-fw" aria-hidden=true></i> <a class=category-link href="/categories/%E5%8D%9A%E5%AE%A2/">博客</a><span class=sep></span><a class=category-link href="/categories/%E5%8D%9A%E5%AE%A2/%E7%BE%8E%E5%9B%A2%E6%8A%80%E6%9C%AF%E5%9B%A2%E9%98%9F/">美团技术团队</a><span class=sep></span><a class=category-link href="/categories/%E5%8D%9A%E5%AE%A2/%E7%BE%8E%E5%9B%A2%E6%8A%80%E6%9C%AF%E5%9B%A2%E9%98%9F/%E6%9C%80%E8%BF%91%E6%9B%B4%E6%96%B0/">最近更新</a></a></div><div class="new-meta-item date"><a class=notlink><i class="fas fa-calendar-alt fa-fw" aria-hidden=true></i><p>发布于：2021年6月3日</p></a></div><div class="new-meta-item browse leancloud"><a class=notlink><div id=lc-pv data-title="CVPR 2021 _ 基于Transformer的端到端视频实例分割方法" data-path=/p/9da2.html><i class="fas fa-eye fa-fw" aria-hidden=true></i><span id=number><i class="fas fa-circle-notch fa-spin fa-fw" aria-hidden=true></i></span> 次浏览</div></a></div></div></div><div><h2 id=前言>前言</h2><p>实例分割是计算机视觉中的基础问题之一。目前，静态图像中的实例分割业界已经进行了很多的研究，但是对视频的实例分割（Video Instance Segmentation，简称VIS）的研究却相对较少。而真实世界中的摄像头所接收的，无论是自动驾驶背景下车辆实时感知的周围场景，还是网络媒体中的长短视频，大多数都是视频流信息而非纯图像信息。因而研究对视频建模的模型有着十分重要的意义，本文系美团无人配送团队在CVPR2021发表的一篇Oral论文: 《<a target=_blank rel=noopener href=https://arxiv.org/abs/2011.14503>End-to-End Video Instance Segmentation with Transformers</a>》的解读。本届CVPR大会共收到7015篇有效投稿，最终共1663篇论文被接收，论文录用率为23.7%，Oral的录用率仅为4%。</p><h2 id=背景>背景</h2><p>图像的实例分割指的是对静态图像中感兴趣的物体进行检测和分割的任务。视频是包含多帧图像的信息载体，相对于静态图像来说，视频的信息更为丰富，因而建模也更为复杂。不同于静态图像仅含有空间的信息，视频同时含有时间维度的信息，因而更接近对真实世界的刻画。其中，视频的实例分割指的是对视频中感兴趣的物体进行检测、分割和跟踪的任务。如图1所示，第一行为给定视频的多帧图像序列，第二行为视频实例分割的结果，其中相同颜色对应同一个实例。视频实例分割不光要对单帧图像中的物体进行检测和分割，而且要在多帧的维度下找到每个物体的对应关系，即对其进行关联和跟踪。</p><p><img src=https://p0.meituan.net/travelcube/c69baf94f90d6f7020d4272a10930078554707.png class=lazyload data-srcset=https://p0.meituan.net/travelcube/c69baf94f90d6f7020d4272a10930078554707.png srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图1 视频实例分割任务示意" referrerpolicy=no-referrer></p><h2 id=相关工作>相关工作</h2><p>现有的视频实例分割算法通常为包含多模块、多阶段的复杂流程。最早的Mask Track R-CNN[1]算法同时包含实例分割和跟踪两个模块，通过在图像实例分割算法Mask R-CNN[2]的网络之上增加一个跟踪的分支实现，该分支主要用于实例特征的提取。在预测阶段，该方法利用外部Memory模块进行多帧实例特征的存储，并将该特征作为实例关联的一个要素进行跟踪。该方法的本质仍然是单帧的分割加传统方法进行跟踪关联。Maskprop[3]在Mask Track R-CNN的基础上增加了Mask Propagation的模块以提升分割Mask生成和关联的质量，该模块可以实现当前帧提取的mask到周围帧的传播，但由于帧的传播依赖于预先计算的单帧的分割Mask，因此要得到最终的分割Mask需要多步的Refinement。该方法的本质仍然是单帧的提取加帧间的传播，且由于其依赖多个模型的组合，方法较为复杂，速度也更慢。</p><p>Stem-seg[4]将视频实例分割划分为实例的区分和类别的预测两个模块。为了实现实例的区分，模型将视频的多帧Clip构建为3D Volume，通过对像素点的Embedding特征进行聚类实现不同物体的分割。由于上述聚类过程不包含实例类别的预测，因此需要额外的语义分割模块提供像素的类别信息。根据以上描述，现有的算法大多沿袭单帧图像实例分割的思想，将视频实例分割任务划分为单帧的提取和多帧的关联多个模块，针对单个任务进行监督和学习，处理速度较慢且不利于发挥视频时序连续性的优势。本文旨在提出一个端到端的模型，将实例的检测、分割和跟踪统一到一个框架下实现，有助于更好地挖掘视频整体的空间和时序信息，且能够以较快的速度解决视频实例分割的问题。</p><h2 id=vistr算法介绍>VisTR算法介绍</h2><h3 id=重新定义问题>重新定义问题</h3><p>首先，我们对视频实例分割这一任务进行了重新的思考。相较于单帧图像，视频含有关于每个实例更为完备和丰富的信息，比如不同实例的轨迹和运动模态，这些信息能够帮助克服单帧实例分割任务中一些比较困难的问题，比如外观相似、物体邻近或者存在遮挡的情形等。另一方面，多帧所提供的关于单个实例更好的特征表示也有助于模型对物体进行更好的跟踪。因此，我们的方法旨在实现一个端到端对视频实例目标进行建模的框架。为了实现这一目标，我们第一个思考是：<strong>视频本身是序列级别的数据，能否直接将其建模为序列预测的任务？</strong>比如，借鉴自然语言处理（NLP）任务的思想，将视频实例分割建模为序列到序列（Seq2Seq）的任务，即给定多帧图像作为输入，直接输出多帧的分割Mask序列，这时需要一个能够同时对多帧进行建模的模型。</p><p>第二个思考是：<strong>视频的实例分割实际同时包含实例分割和目标跟踪两个任务，能否将其统一到一个框架下实现？</strong>针对这个我们的想法是：分割本身是像素特征之间相似度的学习，而跟踪本质是实例特征之间相似度的学习，因此理论上他们可以统一到同一个相似度学习的框架之下。</p><p>基于以上的思考，我们选取了一个同时能够进行序列的建模和相似度学习的模型，即自然语言处理中的Transformer[5]模型。Transformer本身可以用于Seq2Seq的任务，即给定一个序列，可以输入一个序列。并且该模型十分擅长对长序列进行建模，因此非常适合应用于视频领域对多帧序列的时序信息进行建模。其次，Transformer的核心机制，自注意力模块（Self-Attention），可以基于两两之间的相似度来进行特征的学习和更新，使得将像素特征之间相似度以及实例特征之间相似度统一在一个框架内实现成为可能。以上的特性使得Transformer成为VIS任务的恰当选择。除此之外，Transformer已经有被应用于计算机视觉中进行目标检测的实践DETR[6]。因此我们基于transformer设计了视频实例分割（VIS）的模型VisTR。</p><h3 id=vistr算法流程>VisTR算法流程</h3><p><img src=https://p1.meituan.net/travelcube/caf943e826a8e990d50880547946b286560282.png class=lazyload data-srcset=https://p1.meituan.net/travelcube/caf943e826a8e990d50880547946b286560282.png srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图2 VisTR算法框架" referrerpolicy=no-referrer></p><p>遵照上述思想，VisTR的整体框架如图2所示。图中最左边表示输入的多帧原始图像序列（以三帧为例），右边表示输出的实例预测序列，其中相同形状对应同一帧图像的输出，相同颜色对应同一个物体实例的输出。给定多帧图像序列，首先利用卷积神经网络（CNN）进行初始图像特征的提取，然后将多帧的特征结合作为特征序列输入Transformer进行建模，实现序列的输入和输出。</p><p>不难看出，首先，VisTR是一个端到端的模型，即同时对多帧数据进行建模。建模的方式即：将其变为一个Seq2Seq的任务，输入多帧图像序列，模型可以直接输出预测的实例序列。虽然在时序维度多帧的输入和输出是有序的，但是单帧输入的实例的序列在初始状态下是无序的，这样仍然无法实现实例的跟踪关联，因此我们强制使得每帧图像输出的实例的顺序是一致的（用图中同一形状的符号有着相同的颜色变化顺序表示），这样只要找到对应位置的输出，便可自然而然实现同一实例的关联，无需任何后处理操作。为了实现此目标，需要对属于同一个实例位置处的特征进行序列维度的建模。针对性地，为了实现序列级别的监督，我们提出了Instance Sequence Matching的模块。同时为了实现序列级别的分割，我们提出了Instance Sequence Segmentation的模块。端到端的建模将视频的空间和时间特征当做一个整体，可以从全局的角度学习整个视频的信息，同时Transformer所建模的密集特征序列又能够较好的保留细节的信息。</p><h3 id=vistr网络结构>VisTR网络结构</h3><p><img src=https://p0.meituan.net/travelcube/4c97e1eed33085b3e0cd33ce8902031a458423.png class=lazyload data-srcset=https://p0.meituan.net/travelcube/4c97e1eed33085b3e0cd33ce8902031a458423.png srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图3 VisTR网络结构" referrerpolicy=no-referrer></p><p>VisTR的详细网络结构如图3所示，以下是对网络的各个组成部分的介绍：</p><ul><li><strong>Backbone</strong>：主要用于初始图像特征的提取。针对序列的每一帧输入图像，首先利用CNN的Backbone进行初始图像特征的提取，提取的多帧图像特征沿时序和空间维度序列化为多帧特征序列。由于序列化的过程损失了像素原始的空间和时序信息，而检测和分割的任务对于位置信息十分敏感，因此我们将其原始的空间和水平位置进行编码，作为Positional Encoding叠加到提取的序列特征上，以保持原有的位置信息。Positional Encoding的方式遵照Image Transformer[7]的方式，只是将二维的原始位置信息变为了三维的位置信息，这部分在论文中有详细的说明。</li><li><strong>Encoder</strong>：主要用于对多帧特征序列进行整体的建模和更新。输入前面的多帧特征序列，Transformer的Encoder模块利用Self-Attention模块，通过点和点之间相似度的学习，进行序列中所有特征的融合和更新。该模块通过对时序和空间特征的整体建模，能够对属于同一个实例的特征进行更好的学习和增强。</li><li><strong>Decoder</strong>：主要用于解码输出预测的实例特征序列。由于Encoder输入Decoder的是密集的像素特征序列，为了解码出稀疏的实例特征，我们参考DETR的方式，引入Instance Query进行代表性的实例特征的解码。Instance Query是网络自身学习的Embedding参数，用于和密集的输入特征序列进行Attention运算选取能够代表每个实例的特征。以处理3帧图像，每帧图像预测4个物体为例，模型一共需要12个Instance Query，用于解码12个实例预测。和前面的表示一致，用同样的形状表示对应同一帧图像的预测，同样的颜色表示同一个物体实例在不同帧的预测。通过这种方式，我们可以构造出每个实例的预测序列，对应为图3中的Instance 1…Instance 4，后续过程中模型都将单个物体实例的序列看作整体进行处理。</li><li><strong>Instance Sequence Matching</strong>：主要用于对输入的预测结果进行序列级别的匹配和监督。前面已经介绍了从序列的图像输入到序列的实例预测的过程。但是预测序列的顺序其实是基于一个假设的，即在帧的维度保持帧的输入顺序，而在每帧的预测中，不同实例的输出顺序保持一致。帧的顺序比较容易保持，只要控制输入和输出的顺序一致即可，但是不同帧内部实例的顺序其实是没有保证的，因此我们需要设计专门的监督模块来维持这个顺序。在通用目标检测之中，在每个位置点会有它对应的Anchor，因此对应每个位置点的Ground Truth监督是分配好的，而在我们的模型中，实际上是没有Anchor和位置的显式信息，因此对于每个输入点我们没有现成的属于哪个实例的监督信息。为了找到这个监督，并且直接在序列维度进行监督，我们提出了Instance Sequence Matching的模块，这个模块将每个实例的预测序列和标注数据中每个实例的Ground Truth序列进行二分匹配，利用匈牙利匹配的方式找到每个预测最近的标注数据，作为它的Groud Truth进行监督，进行后面的Loss计算和学习。</li><li><strong>Instance Sequence Segmentation</strong>：主要用于获取最终的分割结果序列。前面已经介绍了Seq2Seq的序列预测过程，我们的模型已经能够完成序列的预测和跟踪关联。但是到目前为止，我们为每个实例找到的只是一个代表性的特征向量，而最终要解决的是分割的任务，如何将这个特征向量变为最终的Mask序列，就是Instance Sequence Segmentation模块要解决的问题。前面已经提到，实例分割本质是像素相似度的学习，因此我们初始计算Mask的方式就是利用实例的预测和Encode之后的特征图计算Self-Attention相似度，将得到的相似度图作为这个实例对应帧的初始Attention Mask特征。为了更好的利用时序的信息，我们将属于同一个实例的多帧的Attention Mask 作为Mask序列输入3D卷积模块进行分割，直接得到最终的分割序列。这种方式通过利用多帧同一实例的特征对单帧的分割结果进行增强，可以最大化的发挥时序的优势。</li></ul><h3 id=vistr损失函数>VisTR损失函数</h3><p>根据前面的描述，网络学习中需要计算损失的主要有两个地方，一个是Instance Sequence Matching阶段的匹配过程，一个是找到监督之后最终整个网络的损失函数计算过程。</p><p>Instance Sequence Matching过程的计算公式如式1所示：由于Matching阶段只是用于寻找监督，而计算Mask之间的距离运算比较密集，因此在此阶段我们只考虑Box和预测的类别c两个因素。第一行中的yi表示对应第i个实例的Ground Truth序列，其中c表示类别，b表示Boundingbox，T表示帧数，即T帧该实例对应的类别和Bounding Box序列。第二行和第三行分别表示预测序列的结果，其中p表示在ci这个类别的预测的概率，b表示预测的Bounding Box。序列之间距离的运算是通过两个序列对应位置的值两两之间计算损失函数得到的，图中用Lmatch表示，对于每个预测的序列，找到Lmatch最低那个Ground Truth序列作为它的监督。根据对应的监督信息，就可以计算整个网络的损失函数。</p><p><img src=https://p0.meituan.net/travelcube/0de3104e842d63677fc646dd8dbc4a93294484.png class=lazyload data-srcset=https://p0.meituan.net/travelcube/0de3104e842d63677fc646dd8dbc4a93294484.png srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="公式1 Instance Sequence Matching计算过程" referrerpolicy=no-referrer></p><p>由于我们的方法是将分类、检测、分割和跟踪做到一个端到端网络里，因此最终的损失函数也同时包含类别、Bounding Box和Mask三个方面，跟踪通过直接对序列算损失函数体现。公式2表示分割的损失函数，得到了对应的监督结果之后，我们计算对应序列之间的Dice Loss和Focal Loss作为Mask的损失函数。</p><p><img src=https://p1.meituan.net/travelcube/c936a7fa15215e5e9a149040671aaa4930054.png class=lazyload data-srcset=https://p1.meituan.net/travelcube/c936a7fa15215e5e9a149040671aaa4930054.png srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="公式2 分割损失函数" referrerpolicy=no-referrer></p><p>最终的损失函数如公式3所示，为同时包含分类（类别概率）、检测（Bounding Box）以及分割（Mask）的序列损失函数之和。</p><p><img src=https://p1.meituan.net/travelcube/17f99740e0afcce17740a89c82d15aa335004.png class=lazyload data-srcset=https://p1.meituan.net/travelcube/17f99740e0afcce17740a89c82d15aa335004.png srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="公式3 VisTR整体损失函数" referrerpolicy=no-referrer></p><h2 id=实验结果>实验结果</h2><p>为了验证方法的效果，我们在广泛使用的视频实例分割数据集YouTube-VIS上进行了实验，该数据集包含2238个训练视频，302个验证视频以及343个测试视频，以及40个物体类别。模型的评估标准包含AP和AR，以视频维度多帧Mask之间的IOU作为阈值。</p><h3 id=时序信息的重要性>时序信息的重要性</h3><p>相对于现有的方法，VisTR的最大区别是直接对视频进行建模，而视频和图像的主要区别在于视频包含着丰富的时序信息，如果有效的挖掘和学习时序信息是视频理解的关键，因此我们首先探究了时序信息的重要性。时序包含两个维度：时序的多少（帧数）以及有序和无序的对比。</p><p><img src=https://p0.meituan.net/travelcube/89f994771d084ec150b860b5b606496450087.png class=lazyload data-srcset=https://p0.meituan.net/travelcube/89f994771d084ec150b860b5b606496450087.png srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="表1 不同帧数模型的训练效果对比" referrerpolicy=no-referrer></p><p>表1中展示了我们利用不同帧数的Clip训练模型最终的测试效果，不难看出，随着帧数从18提升至36，模型的精度AP也在不断提升，证明多帧提供的更丰富的时序信息对模型的学习有所帮助。</p><p><img src=https://p0.meituan.net/travelcube/8312a5ec4343d1ad7ffc9a812177b95730022.png class=lazyload data-srcset=https://p0.meituan.net/travelcube/8312a5ec4343d1ad7ffc9a812177b95730022.png srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="表2 打乱时序vs.按照时序训练的效果对比" referrerpolicy=no-referrer></p><p>表2中展示了利用打乱物理时序的Clip以及按照物理时序的Clip进行模型训练的效果对比，可以看出，按照时间顺序训练的模型有一个点的提升，证明VisTR有学到物理时间下物体变化和规律，而按照物理时间顺序对视频建模也有助于视频的理解。</p><h3 id=query探究>Query探究</h3><p>第二个实验是对于Query的探究。由于我们的模型直接建模的36帧图像，对每帧图像预测10个物体，因此需要360个Query，对应表3最后一行的结果（Prediction Level）。我们想探究属于同一帧或者同一个实例的Query之间是否存在一定的关联，即是否可以共享。针对这个目标，我们分别设计了Frame Level的实验：即一帧只使用一个Query的特征进行预测，以及Instance level的实验：一个实例只使用一个Query的特征进行预测。</p><p>可以看到，Instance Level的结果只比Prediction Level的结果少一个点，而Frame Level的结果要低20个点，证明不同帧属于同一个Instance的Query可以共享，而同一帧不同Instance的Query信息不可共享。Prediction Level的Query是和输入的图像帧数成正比的，而Instance Level的Query可以实现不依赖输入帧数的模型。只限制模型要预测的Instance个数，不限制输入帧数，这也是未来可以继续研究的方向。除此之外，我们还设计了Video Level的实验，即整个视频只用一个Query的Embedding特征进行预测，这个模型可以实现8.4的AP。</p><p><img src=https://p1.meituan.net/travelcube/5f326b35c82c9c0bed7cfcdc6cb8117065573.png class=lazyload data-srcset=https://p1.meituan.net/travelcube/5f326b35c82c9c0bed7cfcdc6cb8117065573.png srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="表3 不同类型Query的效果对比" referrerpolicy=no-referrer></p><h3 id=其他设计>其他设计</h3><p>以下是实验过程中我们发现有效的其他设计。</p><p><img src=https://p1.meituan.net/travelcube/ce260f4550ea276e727b720096c5caaf31452.png class=lazyload data-srcset=https://p1.meituan.net/travelcube/ce260f4550ea276e727b720096c5caaf31452.png srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="表4 有无positional encoding的实验效果对比" referrerpolicy=no-referrer></p><p>由于在特征序列化的过程中会损失原有的空间和时间信息，我们提供了原始的Positional Encoding特征以保留原有的位置信息。在表5中进行了有无该模块的对比，Positional Encoding提供的位置信息可以带来约5个点的提升。</p><p><img src=https://p0.meituan.net/travelcube/bc340a4da50cfba741ed4150f5f70a6135060.png class=lazyload data-srcset=https://p0.meituan.net/travelcube/bc340a4da50cfba741ed4150f5f70a6135060.png srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="表5 CNN-encoded的特征vs.Transformer-Encoded的特征对分割的效果对比" referrerpolicy=no-referrer></p><p>在分割的过程中，我们通过计算实例的Prediction与Encoded之后特征的Self-Attention来获取初始的Attention Mask。在表6中，我们进行了利用CNN-Encoded的特征和利用Transformer-Encoded的特征进行分割的效果对比，利用Transformer的特征可以提升一个点。证明了Transformer进行全局特征更新的有效性。</p><p><img src=https://p0.meituan.net/travelcube/443061b17ef44ed618601a2f951eff0c29888.png class=lazyload data-srcset=https://p0.meituan.net/travelcube/443061b17ef44ed618601a2f951eff0c29888.png srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="表6 有无3D卷积的实验效果对比" referrerpolicy=no-referrer></p><p>表6中展示了在分割模块有无3D卷积的效果对比，使用3D卷积可以带来一个点的提升，证明了利用时序信息直接对多帧mask分割的有效性。</p><h3 id=可视化结果>可视化结果</h3><p><img src=https://p0.meituan.net/travelcube/9d5f77849cb389996389e34810245d9b2705244.png class=lazyload data-srcset=https://p0.meituan.net/travelcube/9d5f77849cb389996389e34810245d9b2705244.png srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="图4 VisTR可视化效果" referrerpolicy=no-referrer></p><p>VisTR在YouTube-VIS的可视化效果如图4所示，其中每行表示同一个视频的序列，相同颜色对应同一个实例的分割结果。可以看出无论是在 (a).实例存在遮挡（b).实例位置存在相对变化 ©.同类紧邻易混淆的实例 以及 (d).实例处于不同姿态情形下，模型都能够实现较好的分割个跟踪，证明在有挑战性的情况下，VisTR仍具有很好的效果。</p><h3 id=方法对比>方法对比</h3><p><img src=https://p0.meituan.net/travelcube/7086974696f3e497954594f2a729505e150315.png class=lazyload data-srcset=https://p0.meituan.net/travelcube/7086974696f3e497954594f2a729505e150315.png srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" alt="表7 VisTR可视化效果" referrerpolicy=no-referrer></p><p>表7是我们的方法和其他方法在YoutubeVIS数据集上的对比。我们的方法实现了单一模型的最好效果（其中MaskProp包含多个模型的组合），在57.7FPS的速度下实现了40.1的AP。其中前面的27.7指的是加上顺序的Data Loading部分的速度（这部分可以利用并行进行优化），57.7指的是纯模型Inference的速度。由于我们的方法直接对36帧图像同时进行建模，因此相对于同样模型的单帧处理，理想情况下能带来大约36倍的速度提升，更有助于视频模型的广泛应用。</p><h2 id=总结与展望>总结与展望</h2><p>视频实例分割指的是同时对视频中感兴趣的物体进行分类，分割和跟踪的任务。现有的方法通常设计复杂的流程来解决此问题。本文提出了一种基于Transformer的视频实例分割新框架VisTR，该框架将视频实例分割任务视为直接端到端的并行序列解码和预测的问题。给定一个含有多帧图像的视频作为输入，VisTR直接按顺序输出视频中每个实例的掩码序列。该方法的核心是一种新的实例序列匹配和分割的策略，能够在整个序列级别上对实例进行监督和分割。 VisTR将实例分割和跟踪统一到了相似度学习的框架下，从而大大简化了流程。在没有任何trick的情况下，VisTR在所有使用单一模型的方法中获得了最佳效果，并且在YouTube-VIS数据集上实现了最快的速度。</p><p>据我们所知，这是第一个将Transformers应用于视频分割领域的方法。希望我们的方法能够启发更多视频实例分割的研究，同时也希望此框架未来能够应用于更多视频理解的任务。关于论文的更多细节，请参考原文：<a target=_blank rel=noopener href=https://arxiv.org/abs/2011.14503>《End-to-End Video Instance Segmentation with Transformers》</a>，同时代码也已经在GitHub上开源：<a target=_blank rel=noopener href=https://github.com/Epiphqny/VisTR>https://github.com/Epiphqny/VisTR</a>，欢迎大家来了解或使用。</p><h2 id=作者>作者</h2><ul><li>美团无人车配送中心: 钰晴、昭良、保山、申浩等。</li><li>阿德莱德大学：王鑫龙、沈春华。</li></ul><h2 id=参考文献>参考文献</h2><ul><li>Video Instance Segmentation, <a target=_blank rel=noopener href=https://arxiv.org/abs/1905.04804>https://arxiv.org/abs/1905.04804</a>.</li><li>Mask R-CNN, <a target=_blank rel=noopener href=https://arxiv.org/abs/1703.06870>https://arxiv.org/abs/1703.06870</a>.</li><li>Classifying, Segmenting, and Tracking Object Instances in Video with Mask Propagation, <a target=_blank rel=noopener href=https://arxiv.org/abs/1912.04573>https://arxiv.org/abs/1912.04573</a>.</li><li>STEm-Seg: Spatio-temporal Embeddings for Instance Segmentation in Videos, <a target=_blank rel=noopener href=https://arxiv.org/abs/2003.08429>https://arxiv.org/abs/2003.08429</a>.</li><li>Attention Is All You Need, <a target=_blank rel=noopener href=https://arxiv.org/abs/1706.03762>https://arxiv.org/abs/1706.03762</a>.</li><li>End-to-End Object Detection with Transformers, <a target=_blank rel=noopener href=https://arxiv.org/abs/2005.12872>https://arxiv.org/abs/2005.12872</a>.</li><li>Image Transformer, <a target=_blank rel=noopener href=https://arxiv.org/abs/1802.05751>https://arxiv.org/abs/1802.05751</a>.</li></ul><h2 id=招聘信息>招聘信息</h2><p>美团无人车配送中心大量岗位持续招聘中，诚招算法/系统/硬件开发工程师及专家。欢迎感兴趣的同学发送简历至：ai.hr@meituan.com（邮件标题注明：美团无人车团队）。</p></div><div class=footer><div class=copyright><blockquote><p>博客内容遵循 署名-非商业性使用-相同方式共享 4.0 国际 (CC BY-NC-SA 4.0) 协议</p><p>本文永久链接是：<a href=https://news.slqwq.cn/p/9da2.html>https://news.slqwq.cn/p/9da2.html</a></p></blockquote></div></div><div class=article-meta id=bottom><div class=new-meta-box><div class="new-meta-item date" itemprop=dateUpdated datetime=2021-07-11T00:43:41+00:00><a class=notlink><i class="fas fa-edit fa-fw" aria-hidden=true></i><p>更新于：2021年7月11日</p></a></div><div class="new-meta-item share -mob-share-list"><div class="-mob-share-list share-body"><a class=-mob-share-qq rel="external nofollow noopener noreferrer noopener" target=_blank href="http://connect.qq.com/widget/shareqq/index.html?url=https://news.slqwq.cn/p/9da2.html&title=CVPR 2021 _ 基于Transformer的端到端视频实例分割方法 - Hajeekn RSSHUB&pics=https://p0.meituan.net/travelcube/c69baf94f90d6f7020d4272a10930078554707.png&summary="><img src=https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/logo/128/qq.png class=lazyload data-srcset=https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/logo/128/qq.png srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII="></a> <a class=-mob-share-qzone rel="external nofollow noopener noreferrer noopener" target=_blank href="https://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey?url=https://news.slqwq.cn/p/9da2.html&title=CVPR 2021 _ 基于Transformer的端到端视频实例分割方法 - Hajeekn RSSHUB&pics=https://p0.meituan.net/travelcube/c69baf94f90d6f7020d4272a10930078554707.png&summary="><img src=https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/logo/128/qzone.png class=lazyload data-srcset=https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/logo/128/qzone.png srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII="></a> <a class=-mob-share-weibo rel="external nofollow noopener noreferrer noopener" target=_blank href="http://service.weibo.com/share/share.php?url=https://news.slqwq.cn/p/9da2.html&title=CVPR 2021 _ 基于Transformer的端到端视频实例分割方法 - Hajeekn RSSHUB&pics=https://p0.meituan.net/travelcube/c69baf94f90d6f7020d4272a10930078554707.png&summary="><img src=https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/logo/128/weibo.png class=lazyload data-srcset=https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/logo/128/weibo.png srcset="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII="></a></div></div></div></div><div class=prev-next><a class=prev href=/p/16b3.html><p class=title><i class="fas fa-chevron-left" aria-hidden=true></i>ACL 2021｜美团提出基于对比学习的文本表示模型，效果相比BERT-flow提升8%</p><p class=content>尽管基于BERT的模型在NLP诸多下游任务中取得了成功，直接从BERT导出的句向量表示往往被约束在一个很小的区域内，表现出很高的相似度，因而难以直接用于文本语义匹配。为解决BERT原生句...</p></a><a class=next href=/p/4a4b.html><p class=title>得到高研院举办第八期开学典礼 师生同台分享真实挑战解法<i class="fas fa-chevron-right" aria-hidden=true></i></p><p class=content>4月11日，得到高研院第八期开学典礼在上海静安体育中心举行。这是今年3月得到大学升级为得到高研院之后的第一次公开亮相。清华五道口金融学院副院长田轩、华东师范大学教授刘擎、中科院心理研究所...</p></a></div></article></div><aside class=l_side><section class="widget toc-wrapper shadow desktop mobile" id=toc-div><header><i class="fas fa-list fa-fw" aria-hidden=true></i> <span class=name>本文目录</span></header><div class=content><ol class=toc><li class="toc-item toc-level-2"><a class=toc-link href=#%E5%89%8D%E8%A8%80><span class=toc-text>前言</span></a></li><li class="toc-item toc-level-2"><a class=toc-link href=#%E8%83%8C%E6%99%AF><span class=toc-text>背景</span></a></li><li class="toc-item toc-level-2"><a class=toc-link href=#%E7%9B%B8%E5%85%B3%E5%B7%A5%E4%BD%9C><span class=toc-text>相关工作</span></a></li><li class="toc-item toc-level-2"><a class=toc-link href=#vistr%E7%AE%97%E6%B3%95%E4%BB%8B%E7%BB%8D><span class=toc-text>VisTR算法介绍</span></a><ol class=toc-child><li class="toc-item toc-level-3"><a class=toc-link href=#%E9%87%8D%E6%96%B0%E5%AE%9A%E4%B9%89%E9%97%AE%E9%A2%98><span class=toc-text>重新定义问题</span></a></li><li class="toc-item toc-level-3"><a class=toc-link href=#vistr%E7%AE%97%E6%B3%95%E6%B5%81%E7%A8%8B><span class=toc-text>VisTR算法流程</span></a></li><li class="toc-item toc-level-3"><a class=toc-link href=#vistr%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84><span class=toc-text>VisTR网络结构</span></a></li><li class="toc-item toc-level-3"><a class=toc-link href=#vistr%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0><span class=toc-text>VisTR损失函数</span></a></li></ol></li><li class="toc-item toc-level-2"><a class=toc-link href=#%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C><span class=toc-text>实验结果</span></a><ol class=toc-child><li class="toc-item toc-level-3"><a class=toc-link href=#%E6%97%B6%E5%BA%8F%E4%BF%A1%E6%81%AF%E7%9A%84%E9%87%8D%E8%A6%81%E6%80%A7><span class=toc-text>时序信息的重要性</span></a></li><li class="toc-item toc-level-3"><a class=toc-link href=#query%E6%8E%A2%E7%A9%B6><span class=toc-text>Query探究</span></a></li><li class="toc-item toc-level-3"><a class=toc-link href=#%E5%85%B6%E4%BB%96%E8%AE%BE%E8%AE%A1><span class=toc-text>其他设计</span></a></li><li class="toc-item toc-level-3"><a class=toc-link href=#%E5%8F%AF%E8%A7%86%E5%8C%96%E7%BB%93%E6%9E%9C><span class=toc-text>可视化结果</span></a></li><li class="toc-item toc-level-3"><a class=toc-link href=#%E6%96%B9%E6%B3%95%E5%AF%B9%E6%AF%94><span class=toc-text>方法对比</span></a></li></ol></li><li class="toc-item toc-level-2"><a class=toc-link href=#%E6%80%BB%E7%BB%93%E4%B8%8E%E5%B1%95%E6%9C%9B><span class=toc-text>总结与展望</span></a></li><li class="toc-item toc-level-2"><a class=toc-link href=#%E4%BD%9C%E8%80%85><span class=toc-text>作者</span></a></li><li class="toc-item toc-level-2"><a class=toc-link href=#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE><span class=toc-text>参考文献</span></a></li><li class="toc-item toc-level-2"><a class=toc-link href=#%E6%8B%9B%E8%81%98%E4%BF%A1%E6%81%AF><span class=toc-text>招聘信息</span></a></li></ol></div></section></aside><script>
  window.pdata={}
  pdata.ispage=true;
  pdata.postTitle="CVPR 2021 _ 基于Transformer的端到端视频实例分割方法";
  pdata.commentPath="";
  pdata.commentPlaceholder="";
  // header 这里无论是否开启pjax都需要
  var l_header=document.getElementById("l_header");
  
  l_header.classList.add("show");
  
  
    // cover
    var cover_wrapper=document.querySelector('.cover-wrapper');
    
    cover_wrapper.id="none";
    cover_wrapper.style.display="none";
    
  
</script></div><footer class="footer clearfix"><br><br><div class=aplayer-container></div><br><div class=social-wrapper></div><div><p>博客内容遵循 <a target=_blank rel=noopener href=https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh>署名-非商业性使用-相同方式共享 4.0 国际 (CC BY-NC-SA 4.0) 协议</a></p></div><div><p><span id=lc-sv>本站总访问量为<span id=number><i class="fas fa-circle-notch fa-spin fa-fw" aria-hidden=true></i></span> 次</span> <span id=lc-uv>访客数为<span id=number><i class="fas fa-circle-notch fa-spin fa-fw" aria-hidden=true></i></span> 人</span></p></div>本站使用 <a href=https://github.com/volantis-x/hexo-theme-volantis/tree/4.3.1 target=_blank class=codename>Volantis</a> 作为主题<div class=copyright><p><a href="/">Copyright © 2017-2020 XXX</a></p></div></footer><a id=s-top class="fas fa-arrow-up fa-fw" href=javascript:void(0)></a></div></div><div><script>
/************这个文件存放不需要重载的全局变量和全局函数*********/
window.volantis={};
window.volantis.loadcss=document.getElementById("loadcss");
/******************** Pjax ********************************/
function VPjax(){
	this.list=[] // 存放回调函数
	this.start=()=>{
	  for(var i=0;i<this.list.length;i++){
		this.list[i].run();
	  }
	}
	this.push=(fn,name)=>{
		var f=new PjaxItem(fn,name);
		this.list.push(f);
	}
	// 构造一个可以run的对象
	function PjaxItem(fn,name){
		// 函数名称
		this.name = name || fn.name
		// run方法
		this.run=()=>{
			fn()
		}
	}
}
volantis.pjax={}
volantis.pjax.method={
	complete: new VPjax(),
	error: new VPjax(),
	send: new VPjax()
}
volantis.pjax={
	...volantis.pjax,
	push: volantis.pjax.method.complete.push,
	error: volantis.pjax.method.error.push,
	send: volantis.pjax.method.send.push
}
/********************脚本懒加载函数********************************/
// 已经加入了setTimeout
function loadScript(src, cb) {
	setTimeout(function() {
		var HEAD = document.getElementsByTagName('head')[0] || document.documentElement;
		var script = document.createElement('script');
		script.setAttribute('type','text/javascript');
		if (cb) script.onload = cb;
		script.setAttribute('src', src);
		HEAD.appendChild(script);
	});
}
//https://github.com/filamentgroup/loadCSS
var loadCSS = function( href, before, media, attributes ){
	var doc = window.document;
	var ss = doc.createElement( "link" );
	var ref;
	if( before ){
		ref = before;
	}
	else {
		var refs = ( doc.body || doc.getElementsByTagName( "head" )[ 0 ] ).childNodes;
		ref = refs[ refs.length - 1];
	}
	var sheets = doc.styleSheets;
	if( attributes ){
		for( var attributeName in attributes ){
			if( attributes.hasOwnProperty( attributeName ) ){
				ss.setAttribute( attributeName, attributes[attributeName] );
			}
		}
	}
	ss.rel = "stylesheet";
	ss.href = href;
	ss.media = "only x";
	function ready( cb ){
		if( doc.body ){
			return cb();
		}
		setTimeout(function(){
			ready( cb );
		});
	}
	ready( function(){
		ref.parentNode.insertBefore( ss, ( before ? ref : ref.nextSibling ) );
	});
	var onloadcssdefined = function( cb ){
		var resolvedHref = ss.href;
		var i = sheets.length;
		while( i-- ){
			if( sheets[ i ].href === resolvedHref ){
				return cb();
			}
		}
		setTimeout(function() {
			onloadcssdefined( cb );
		});
	};
	function loadCB(){
		if( ss.addEventListener ){
			ss.removeEventListener( "load", loadCB );
		}
		ss.media = media || "all";
	}
	if( ss.addEventListener ){
		ss.addEventListener( "load", loadCB);
	}
	ss.onloadcssdefined = onloadcssdefined;
	onloadcssdefined( loadCB );
	return ss;
};
</script><script>
  
  loadCSS("https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.14/css/all.min.css", window.volantis.loadcss);
  
  
  
  
</script><script src=https://cdn.jsdelivr.net/npm/jquery@3.5/dist/jquery.min.js></script><script>
  function pjax_fancybox() {
    $(".md .gallery").find("img").each(function () { //渲染 fancybox
      var element = document.createElement("a"); // a 标签
      $(element).attr("class", "fancybox");
      $(element).attr("pjax-fancybox", "");  // 过滤 pjax
      $(element).attr("href", $(this).attr("src"));
      if ($(this).attr("data-original")) {
        $(element).attr("href", $(this).attr("data-original"));
      }
      $(element).attr("data-fancybox", "images");
      var caption = "";   // 描述信息
      if ($(this).attr('alt')) {  // 判断当前页面是否存在描述信息
        $(element).attr('data-caption', $(this).attr('alt'));
        caption = $(this).attr('alt');
      }
      var div = document.createElement("div");
      $(div).addClass("fancybox");
      $(this).wrap(div); // 最外层套 div ，其实主要作用还是 class 样式
      var span = document.createElement("span");
      $(span).addClass("image-caption");
      $(span).text(caption); // 加描述
      $(this).after(span);  // 再套一层描述
      $(this).wrap(element);  // 最后套 a 标签
    })
    $(".md .gallery").find("img").fancybox({
      selector: '[data-fancybox="images"]',
      hash: false,
      loop: false,
      closeClick: true,
      helpers: {
        overlay: {closeClick: true}
      },
      buttons: [
        "zoom",
        "close"
      ]
    });
  };
  function SCload_fancybox() {
    if ($(".md .gallery").find("img").length == 0) return;
    loadCSS("https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css", document.getElementById("loadcss"));
    loadScript('https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js', pjax_fancybox)
  };
  $(function () {
    SCload_fancybox();
  });
  function Pjax_SCload_fancybox(){
	if (typeof $.fancybox == "undefined") {
	 SCload_fancybox();
    } else {
	 pjax_fancybox();
    }
  }
  volantis.pjax.push(Pjax_SCload_fancybox)
  volantis.pjax.send(()=>{
      if (typeof $.fancybox != "undefined") {
        $.fancybox.close();    // 关闭弹窗
      }
  },'fancybox')
</script><script>
  function loadIssuesJS() {
    if ($(".md").find(".issues-api").length == 0) return;
	
	  loadScript('/js/issues.js');
	
  };
  $(function () {
    loadIssuesJS();
  });
  volantis.pjax.push(()=>{
	if (typeof IssuesAPI == "undefined") {
	  loadIssuesJS();
	}
  },"IssuesJS")
</script><script defer src=https://cdn.jsdelivr.net/npm/vanilla-lazyload@17.1.0/dist/lazyload.min.js></script><script>
  // https://www.npmjs.com/package/vanilla-lazyload
  // Set the options globally
  // to make LazyLoad self-initialize
  window.lazyLoadOptions = {
    elements_selector: ".lazyload",
    threshold: 0
  };
  // Listen to the initialization event
  // and get the instance of LazyLoad
  window.addEventListener(
    "LazyLoad::Initialized",
    function (event) {
      window.lazyLoadInstance = event.detail.instance;
    },
    false
  );
  document.addEventListener('DOMContentLoaded', function () {
    lazyLoadInstance.update();
  });
  document.addEventListener('pjax:complete', function () {
    lazyLoadInstance.update();
  });
</script><script>
  window.FPConfig = {
	delay: 0,
	ignoreKeywords: [],
	maxRPS: 5,
	hoverDelay: 25
  };
</script><script defer src=https://cdn.jsdelivr.net/gh/gijo-varghese/flying-pages@2.1.2/flying-pages.min.js></script><script src=/js/valine.js></script><script>
  function emoji(path, idx, ext) {
    return path + "/" + path + "-" + idx + "." + ext;
  }
  var emojiMaps = {};
  for (var i = 1; i <= 54; i++) {
    emojiMaps['tieba-' + i] = emoji('tieba', i, 'png');
  }
  for (var i = 1; i <= 101; i++) {
    emojiMaps['qq-' + i] = emoji('qq', i, 'gif');
  }
  for (var i = 1; i <= 116; i++) {
    emojiMaps['aru-' + i] = emoji('aru', i, 'gif');
  }
  for (var i = 1; i <= 125; i++) {
    emojiMaps['twemoji-' + i] = emoji('twemoji', i, 'png');
  }
  for (var i = 1; i <= 4; i++) {
    emojiMaps['weibo-' + i] = emoji('weibo', i, 'png');
  }
  function pjax_valine() {
    if(!document.querySelectorAll("#valine_container")[0])return;
    let pagePlaceholder = pdata.commentPlaceholder || "快来评论吧~";
    let path = pdata.commentPath;
    if (path.length == 0) {
      let defaultPath = '';
      path = defaultPath || decodeURI(window.location.pathname);
    }
    var valine = new Valine();
    valine.init(Object.assign({"path":null,"placeholder":"快来评论吧~","appId":null,"appKey":null,"meta":["nick","mail","link"],"requiredFields":["nick","mail"],"enableQQ":true,"recordIP":false,"avatar":"robohash","pageSize":10,"lang":"zh-cn","highlight":true,"mathJax":false}, {
      el: '#valine_container',
      path: path,
      placeholder: pagePlaceholder,
      emojiCDN: 'https://cdn.jsdelivr.net/gh/volantis-x/cdn-emoji/valine/',
      emojiMaps: emojiMaps,
    }))
  }
  $(function () {
    pjax_valine();
  });
  volantis.pjax.push(pjax_valine);
</script><script src=/js/app.js></script><script>
const SearchServiceimagePath="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@master/img/";
const ROOT =  ("/" || "/").endsWith('/') ? ("/" || "/") : ("//" || "/" );

$('.input.u-search-input').one('focus',function(){
	
		loadScript('/js/search/hexo.js',setSearchService);
	
})

function listenSearch(){
  
    customSearch = new HexoSearch({
      imagePath: SearchServiceimagePath
    });
  
}
function setSearchService() {
	listenSearch();
	
}
</script><script defer>

  const LCCounter = {
    app_id: 'u9j57bwJod4EDmXWdxrwuqQT-MdYXbMMI',
    app_key: 'jfHtEKVE24j0IVCGHbvuFClp',
    custom_api_server: '',

    // 查询存储的记录
    getRecord(Counter, url, title) {
      return new Promise(function (resolve, reject) {
        Counter('get', '/classes/Counter?where=' + encodeURIComponent(JSON.stringify({url})))
          .then(resp => resp.json())
          .then(({results, code, error}) => {
            if (code === 401) {
              throw error;
            }
            if (results && results.length > 0) {
              var record = results[0];
              resolve(record);
            } else {
              Counter('post', '/classes/Counter', {url, title: title, times: 0})
                .then(resp => resp.json())
                .then((record, error) => {
                  if (error) {
                    throw error;
                  }
                  resolve(record);
                }).catch(error => {
                console.error('Failed to create', error);
                reject(error);
              });
            }
          }).catch((error) => {
          console.error('LeanCloud Counter Error:', error);
          reject(error);
        });
      })
    },

    // 发起自增请求
    increment(Counter, incrArr) {
      return new Promise(function (resolve, reject) {
        Counter('post', '/batch', {
          "requests": incrArr
        }).then((res) => {
          res = res.json();
          if (res.error) {
            throw res.error;
          }
          resolve(res);
        }).catch((error) => {
          console.error('Failed to save visitor count', error);
          reject(error);
        });
      });
    },

    // 构建自增请求体
    buildIncrement(objectId) {
      return {
        "method": "PUT",
        "path": `/1.1/classes/Counter/${ objectId }`,
        "body": {
          "times": {
            '__op': 'Increment',
            'amount': 1
          }
        }
      }
    },

    // 校验是否为有效的 UV
    validUV() {
      var key = 'LeanCloudUVTimestamp';
      var flag = localStorage.getItem(key);
      if (flag) {
        // 距离标记小于 24 小时则不计为 UV
        if (new Date().getTime() - parseInt(flag) <= 86400000) {
          return false;
        }
      }
      localStorage.setItem(key, new Date().getTime().toString());
      return true;
    },

    addCount(Counter) {
      var enableIncr = '' === 'true' && window.location.hostname !== 'localhost';
      enableIncr = true;
      var getterArr = [];
      var incrArr = [];
      // 请求 PV 并自增
      var pvCtn = document.querySelector('#lc-sv');
      if (pvCtn || enableIncr) {
        var pvGetter = this.getRecord(Counter, 'https://news.slqwq.cn' + '/#lc-sv', 'Visits').then((record) => {
          incrArr.push(this.buildIncrement(record.objectId))
          var eles = document.querySelectorAll('#lc-sv #number');
          if (eles.length > 0) {
            eles.forEach((el,index,array)=>{
              el.innerText = record.times + 1;
              if (pvCtn) {
                pvCtn.style.display = 'inline';
              }
            })
          }
        });
        getterArr.push(pvGetter);
      }

      // 请求 UV 并自增
      var uvCtn = document.querySelector('#lc-uv');
      if (uvCtn || enableIncr) {
        var uvGetter = this.getRecord(Counter, 'https://news.slqwq.cn' + '/#lc-uv', 'Visitors').then((record) => {
          var vuv = this.validUV();
          vuv && incrArr.push(this.buildIncrement(record.objectId))
          var eles = document.querySelectorAll('#lc-uv #number');
          if (eles.length > 0) {
            eles.forEach((el,index,array)=>{
              el.innerText = record.times + (vuv ? 1 : 0);
              if (uvCtn) {
                uvCtn.style.display = 'inline';
              }
            })
          }
        });
        getterArr.push(uvGetter);
      }

      // 请求文章的浏览数，如果是当前页面就自增
      var allPV = document.querySelectorAll('#lc-pv');
      if (allPV.length > 0 || enableIncr) {
        for (i = 0; i < allPV.length; i++) {
          let pv = allPV[i];
          let title = pv.getAttribute('data-title');
          var url = 'https://news.slqwq.cn' + pv.getAttribute('data-path');
          if (url) {
            var viewGetter = this.getRecord(Counter, url, title).then((record) => {
              // 是当前页面就自增
              let curPath = window.location.pathname;
              if (curPath.includes('index.html')) {
                curPath = curPath.substring(0, curPath.lastIndexOf('index.html'));
              }
              if (pv.getAttribute('data-path') == curPath) {
                incrArr.push(this.buildIncrement(record.objectId));
              }
              if (pv) {
                var ele = pv.querySelector('#lc-pv #number');
                if (ele) {
                  if (pv.getAttribute('data-path') == curPath) {
                    ele.innerText = (record.times || 0) + 1;
                  } else {
                    ele.innerText = record.times || 0;
                  }
                  pv.style.display = 'inline';
                }
              }
            });
            getterArr.push(viewGetter);
          }
        }
      }

      // 如果启动计数自增，批量发起自增请求
      if (enableIncr) {
        Promise.all(getterArr).then(() => {
          incrArr.length > 0 && this.increment(Counter, incrArr);
        })
      }

    },


    fetchData(api_server) {
      var Counter = (method, url, data) => {
        return fetch(`${ api_server }/1.1${ url }`, {
          method,
          headers: {
            'X-LC-Id': this.app_id,
            'X-LC-Key': this.app_key,
            'Content-Type': 'application/json',
          },
          body: JSON.stringify(data)
        });
      };
      this.addCount(Counter);
    },

    refreshCounter() {
      var api_server = this.app_id.slice(-9) !== '-MdYXbMMI' ? this.custom_api_server : `https://${ this.app_id.slice(0, 8).toLowerCase() }.api.lncldglobal.com`;
      if (api_server) {
        this.fetchData(api_server);
      } else {
        fetch('https://app-router.leancloud.cn/2/route?appId=' + this.app_id)
          .then(resp => resp.json())
          .then(({api_server}) => {
            this.fetchData('https://' + api_server);
          });
      }
    }

  };

  LCCounter.refreshCounter();

  document.addEventListener('pjax:complete', function () {
    LCCounter.refreshCounter();
  });
</script><script>
const rootElement = document.documentElement;
const darkModeStorageKey = "user-color-scheme";
const rootElementDarkModeAttributeName = "data-user-color-scheme";

const setLS = (k, v) => {
    localStorage.setItem(k, v);
};

const removeLS = (k) => {
    localStorage.removeItem(k);
};

const getLS = (k) => {
    return localStorage.getItem(k);
};

const getModeFromCSSMediaQuery = () => {
  return window.matchMedia("(prefers-color-scheme: dark)").matches
    ? "dark"
    : "light";
};

const resetRootDarkModeAttributeAndLS = () => {
  rootElement.removeAttribute(rootElementDarkModeAttributeName);
  removeLS(darkModeStorageKey);
};

const validColorModeKeys = {
  dark: true,
  light: true,
};

const applyCustomDarkModeSettings = (mode) => {
  const currentSetting = mode || getLS(darkModeStorageKey);

  if (currentSetting === getModeFromCSSMediaQuery()) {
    resetRootDarkModeAttributeAndLS();
  } else if (validColorModeKeys[currentSetting]) {
    rootElement.setAttribute(rootElementDarkModeAttributeName, currentSetting);
  } else {
    resetRootDarkModeAttributeAndLS();
  }
};

const invertDarkModeObj = {
  dark: "light",
  light: "dark",
};

/**
 * get target mode
 */
const toggleCustomDarkMode = () => {
  let currentSetting = getLS(darkModeStorageKey);

  if (validColorModeKeys[currentSetting]) {
    currentSetting = invertDarkModeObj[currentSetting];
  } else if (currentSetting === null) {
    currentSetting = invertDarkModeObj[getModeFromCSSMediaQuery()];
  } else {
    return;
  }
  setLS(darkModeStorageKey, currentSetting);
  return currentSetting;
};

/**
 * bind click event for toggle button
 */
var btn=$("#wrapper .toggle-mode-btn,#rightmenu-wrapper .toggle-mode-btn");
function bindToggleButton() {
    btn.on('click',(e) => {
      const mode = toggleCustomDarkMode();
      applyCustomDarkModeSettings(mode);
    });
}

applyCustomDarkModeSettings();
document.addEventListener("DOMContentLoaded", bindToggleButton);
volantis.pjax.push(bindToggleButton);
volantis.pjax.send(()=>{
	btn.unbind('click');
},'toggle-mode-btn-unbind');
</script><script>
function listennSidebarTOC() {
  const navItems = document.querySelectorAll(".toc li");
  if (!navItems.length) return;
  const sections = [...navItems].map((element) => {
    const link = element.querySelector(".toc-link");
    const target = document.getElementById(
      decodeURI(link.getAttribute("href")).replace("#", "")
    );
    link.addEventListener("click", (event) => {
      event.preventDefault();
      window.scrollTo({
		top: target.offsetTop + 100,
		
		behavior: "smooth"
		
	  });
    });
    return target;
  });

  function activateNavByIndex(target) {
    if (target.classList.contains("active-current")) return;

    document.querySelectorAll(".toc .active").forEach((element) => {
      element.classList.remove("active", "active-current");
    });
    target.classList.add("active", "active-current");
    let parent = target.parentNode;
    while (!parent.matches(".toc")) {
      if (parent.matches("li")) parent.classList.add("active");
      parent = parent.parentNode;
    }
  }

  function findIndex(entries) {
    let index = 0;
    let entry = entries[index];
    if (entry.boundingClientRect.top > 0) {
      index = sections.indexOf(entry.target);
      return index === 0 ? 0 : index - 1;
    }
    for (; index < entries.length; index++) {
      if (entries[index].boundingClientRect.top <= 0) {
        entry = entries[index];
      } else {
        return sections.indexOf(entry.target);
      }
    }
    return sections.indexOf(entry.target);
  }

  function createIntersectionObserver(marginTop) {
    marginTop = Math.floor(marginTop + 10000);
    let intersectionObserver = new IntersectionObserver(
      (entries, observe) => {
        let scrollHeight = document.documentElement.scrollHeight + 100;
        if (scrollHeight > marginTop) {
          observe.disconnect();
          createIntersectionObserver(scrollHeight);
          return;
        }
        let index = findIndex(entries);
        activateNavByIndex(navItems[index]);
      },
      {
        rootMargin: marginTop + "px 0px -100% 0px",
        threshold: 0,
      }
    );
    sections.forEach((element) => {
      element && intersectionObserver.observe(element);
    });
  }
  createIntersectionObserver(document.documentElement.scrollHeight);
}

document.addEventListener("DOMContentLoaded", listennSidebarTOC);
document.addEventListener("pjax:success", listennSidebarTOC);
</script><script src=https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.min.js></script><script>
    var pjax;
    document.addEventListener('DOMContentLoaded', function () {
      pjax = new Pjax({
        elements: 'a[href]:not([href^="#"]):not([href="javascript:void(0)"]):not([pjax-fancybox])',
        selectors: [
          "title",
          
          "#pjax-container",
          "#pjax-header-nav-list"
        ],
        cacheBust: false,   // url 地址追加时间戳，用以避免浏览器缓存
        timeout: 5000
      });
    });

    document.addEventListener('pjax:send', function (e) {
      //window.stop(); // 相当于点击了浏览器的停止按钮

      try {
        var currentUrl = window.location.pathname;
        var targetUrl = e.triggerElement.href;
        var banUrl = [""];
        if (banUrl[0] != "") {
          banUrl.forEach(item => {
            if(currentUrl.indexOf(item) != -1 || targetUrl.indexOf(item) != -1) {
              window.location.href = targetUrl;
            }
          });
        }
      } catch (error) {}

      window.subData = null; // 移除标题（用于一二级导航栏切换处）

      volantis.$switcher.removeClass('active'); // 关闭移动端激活的搜索框
      volantis.$header.removeClass('z_search-open'); // 关闭移动端激活的搜索框
      volantis.$wrapper.removeClass('sub'); // 跳转页面时关闭二级导航

      // 解绑事件 避免重复监听
      volantis.$topBtn.unbind('click');
      $('.menu a').unbind('click');
      $(window).unbind('resize');
      $(window).unbind('scroll');
      $(document).unbind('scroll');
      $(document).unbind('click');
      $('body').unbind('click');
	  // 使用 volantis.pjax.send 方法传入pjax:send回调函数 参见layout/_partial/scripts/global.ejs
	  volantis.pjax.method.send.start();
    });

    document.addEventListener('pjax:complete', function () {
      $('.nav-main').find('.list-v').not('.menu-phone').removeAttr("style",""); // 移除小尾巴的移除
      $('.menu-phone.list-v').removeAttr("style",""); // 移除小尾巴的移除
      $('script[data-pjax], .pjax-reload script').each(function () {
        $(this).parent().append($(this).remove());
      });
      try{
		// 使用 volantis.pjax.push 方法传入重载函数 参见layout/_partial/scripts/global.ejs
		volantis.pjax.method.complete.start();
      } catch (e) {
        console.log(e);
      }
    });

    document.addEventListener('pjax:error', function (e) {
	  // 使用 volantis.pjax.error 方法传入pjax:error回调函数 参见layout/_partial/scripts/global.ejs
	  volantis.pjax.method.error.start();
      window.location.href = e.triggerElement.href;
    });
</script></div></body></html>